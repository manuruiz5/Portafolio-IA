# üìù **Explorando la experimentaci√≥n en redes neuronales: del MLP b√°sico a la optimizaci√≥n avanzada**

## Contexto

En esta pr√°ctica se busca profundizar en la experimentaci√≥n con redes neuronales multicapa (MLP) aplicadas a **datasets de im√°genes complejos** como CIFAR-10.  
Partiendo de un modelo b√°sico, se explorar√° c√≥mo modificar la **arquitectura**, aplicar **t√©cnicas de regularizaci√≥n**, ajustar **optimizadores y tasas de aprendizaje**, y utilizar **callbacks avanzados** para mejorar el rendimiento y la estabilidad del entrenamiento.  

El objetivo es demostrar c√≥mo cada componente y decisi√≥n de dise√±o en un MLP impacta en la **capacidad de aprendizaje, generalizaci√≥n y eficiencia computacional**, proporcionando una base s√≥lida para abordar redes m√°s complejas en el futuro.

---

## üéØ Objetivos

- Configurar un **entorno de experimentaci√≥n estable** con TensorFlow y Keras, preparado para el uso de TensorBoard.  
- Cargar, preprocesar y explorar el **dataset CIFAR-10**, garantizando su correcta divisi√≥n y normalizaci√≥n.  
- Dise√±ar y entrenar un **MLP b√°sico**, observando su comportamiento en un dataset de im√°genes.  
- Analizar c√≥mo la **profundidad, ancho y funciones de activaci√≥n** afectan la precisi√≥n y convergencia del modelo.  
- Evaluar t√©cnicas de **regularizaci√≥n** (Dropout, L2, BatchNormalization) para mejorar la generalizaci√≥n.  
- Comparar el rendimiento de distintos **optimizadores y tasas de aprendizaje**, identificando los m√°s eficientes.  
- Implementar y estudiar el efecto de **callbacks avanzados** (EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard y LearningRateScheduler) en la estabilidad y eficiencia del entrenamiento.  
- Visualizar los resultados y m√©tricas del entrenamiento, interpretando los efectos de cada decisi√≥n en la arquitectura y los hiperpar√°metros.  

---

## Marco Te√≥rico

### Capas densas (Fully Connected / Linear)
- Cada neurona de la capa ve todas las entradas de la capa anterior.
  - Datos tabulares  
  - Embeddings  
  - Capas finales de clasificaci√≥n en CNNs o Transformers
- Forma (shape): Definir correctamente vector de entrada y salida es esencial para calcular conexiones y pesos.

### Batch Normalization (BatchNorm)
- Normaliza activaciones de cada neurona/canal.  
- Permite usar tasas de aprendizaje m√°s altas y acelera la convergencia.  
- Estabiliza los gradientes y mejora la eficiencia del entrenamiento.

## Optimizaci√≥n
- Un **optimizador** ajusta los pesos para minimizar la funci√≥n de p√©rdida.  
- Componentes clave: learning rate, momentum/adaptativo.

### SGD (Stochastic Gradient Descent)
- Actualiza pesos con un paso fijo (learning rate).  
- Puede tambalear en terrenos ruidosos, pero suele generalizar bien.  
- Hiperpar√°metros √∫tiles: lr, momentum (0.9), nesterov=True.

### Adam
- Cada peso tiene su propio paso adaptativo.  
- Ideal para resultados r√°pidos sin mucho ajuste.  
- Hiperpar√°metros t√≠picos: lr=1e-3, betas=(0.9, 0.999), eps=1e-8.

### AdamW
- Variante de Adam donde el decaimiento de pesos (weight decay) est√° separado.  
- Mejor regularizaci√≥n y generalizaci√≥n que Adam.  
- Hiperpar√°metros: lr=3e-4, weight_decay=1e-2, betas=(0.9,0.999), eps=1e-8.

## Callbacks
- **EarlyStopping:** detiene el entrenamiento si la m√©trica de validaci√≥n deja de mejorar; evita sobreajuste.  
- **ReduceLROnPlateau:** reduce learning rate cuando la m√©trica se estanca.  
- **ModelCheckpoint:** guarda el mejor modelo seg√∫n una m√©trica espec√≠fica.  
- **LearningRateScheduler:** permite definir cambios del learning rate a lo largo de las √©pocas.  
- **TensorBoard:** herramienta de visualizaci√≥n de m√©tricas, pesos y activaciones para analizar el entrenamiento.


---

## Actividades

| Actividad                                                    | Resultado esperado                                                                                                                                                                                                                                                              |
| ------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **1. Explorar la Experimentaci√≥n y Preparar Librer√≠as**      | Entorno configurado correctamente con TensorFlow 2.19.0; se verifica disponibilidad de GPU/CPU; TensorBoard listo para uso.                                                                                                                                                     |
| **2. Cargar y Preparar los Datos**                           | Dataset CIFAR-10 cargado y preprocesado; im√°genes aplanadas y normalizadas; divisi√≥n en entrenamiento (45.000), validaci√≥n (5.000) y prueba (10.000) correcta; etiquetas unidimensionales.                                                                                      |
| **3. Construcci√≥n y Entrenamiento de la Red Neuronal (MLP)** | Modelo MLP entrenado con precisi√≥n final en prueba ~46%; curvas de loss y accuracy muestran aprendizaje; TensorBoard refleja histograma de sesgos y m√©tricas de entrenamiento.                                                                                                  |
| **4. Experimentaci√≥n: Capas Densas (Profundidad y Ancho)**   | Se comparan modelos peque√±os, intermedios y grandes; se observa el impacto de profundidad y ancho en precisi√≥n, tiempo de entrenamiento y par√°metros; ReLU como activaci√≥n m√°s eficiente; BatchNormalization y Dropout mejoran la generalizaci√≥n; tama√±o de batch √≥ptimo 32‚Äì64. |
| **5. Experimentaci√≥n: Optimizadores y Tasas de Aprendizaje** | Se comparan Adam, SGD, RMSprop y AdamW; SGD con lr=0.01 logra mejor precisi√≥n en test (51.6%); Adam y AdamW son opciones estables; RMSprop no converge.                                                                                                                         |
| **6. Experimentaci√≥n: Callbacks**                            | Se aplican EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard y LearningRateScheduler; los callbacks mejoran estabilidad, generalizaci√≥n y permiten control de learning rate; se observa la evoluci√≥n de m√©tricas y pesos en TensorBoard.                           |


---

## Desarrollo:

### üßÆ 1. Explorar la Experimentaci√≥n y Preparar Librer√≠as

En este primer paso se configura el **entorno de trabajo** necesario para realizar los experimentos de redes neuronales utilizando **TensorFlow** y **Keras**, junto con herramientas auxiliares de an√°lisis y visualizaci√≥n de datos.  

El objetivo es asegurar que todas las librer√≠as est√©n correctamente cargadas y que el entorno sea **reproducible, estable y preparado** para el uso de **TensorBoard**, la herramienta de seguimiento de entrenamiento.

#### üìä Resultado obtenido

Al ejecutar el c√≥digo, la consola muestra:

TensorFlow: 2.19.0

GPU disponibles: []

Esto confirma que:

- **TensorFlow est√° correctamente instalado** en la versi√≥n **2.19.0**.  
- No se detect√≥ ninguna **GPU disponible**, por lo que el entrenamiento se realizar√° en **CPU**.

### üß† 2. Cargar y Preparar los Datos

En este paso se realiza la **carga, preprocesamiento y exploraci√≥n inicial del conjunto de datos CIFAR-10**, un dataset cl√°sico utilizado para entrenar y evaluar modelos de clasificaci√≥n de im√°genes.  

El objetivo principal es transformar los datos en un formato adecuado para una **red neuronal de tipo MLP (Perceptr√≥n Multicapa)** y garantizar que est√©n correctamente **normalizados, divididos y etiquetados** antes del entrenamiento.

Se utiliz√≥ la funci√≥n `keras.datasets.cifar10.load_data()`, que descarga autom√°ticamente el dataset desde el repositorio oficial. 

CIFAR-10 contiene **60.000 im√°genes a color de 32x32 p√≠xeles**, distribuidas en **10 clases**:

`['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']`

Estas clases se asignaron al arreglo `class_names` para facilitar la visualizaci√≥n y comprensi√≥n de las predicciones del modelo.  

Adem√°s, se aplic√≥ `flatten()` a los vectores `y_train` y `y_test` para **convertir las etiquetas en unidimensionales**, lo cual simplifica el manejo en los procesos posteriores de entrenamiento y evaluaci√≥n.

Se separ√≥ un **10% del conjunto de entrenamiento** como datos de validaci√≥n. 

Esto permite evaluar el rendimiento del modelo durante el entrenamiento sin utilizar los datos de prueba, asegurando una **evaluaci√≥n justa** y evitando el **sobreajuste**.

El conjunto final qued√≥ dividido de la siguiente manera:

- **Entrenamiento:** 45.000 im√°genes  
- **Validaci√≥n:** 5.000 im√°genes  
- **Prueba:** 10.000 im√°genes  


#### üìä Resultado obtenido

- El dataset se descarg√≥ y carg√≥ correctamente.  
- Las dimensiones coinciden con la divisi√≥n realizada (train/val/test).  
- Cada imagen se convirti√≥ correctamente en un vector de 3072 elementos.

### üß© 3. Construcci√≥n y Entrenamiento de la Red Neuronal

En este paso se dise√±a, compila y entrena una **red neuronal completamente conectada (MLP)** utilizando **TensorFlow** y **Keras**.  
El prop√≥sito es que el modelo aprenda a clasificar las im√°genes del conjunto **CIFAR-10** en sus diez categor√≠as posibles, aprovechando los datos previamente normalizados y preparados.


Se cre√≥ un modelo **Sequential**, una estructura lineal de capas donde la salida de una capa sirve como entrada de la siguiente.  
El modelo consta de tres capas principales:

- **Capa densa 1:** 32 neuronas con funci√≥n de activaci√≥n *ReLU*. Procesa los vectores de entrada (im√°genes aplanadas) y permite capturar relaciones no lineales entre los p√≠xeles.  
- **Capa densa 2:** 32 neuronas adicionales con activaci√≥n *ReLU*, que profundiza la capacidad del modelo para representar patrones complejos.  
- **Capa de salida:** 10 neuronas con activaci√≥n *Softmax*, una por cada clase del dataset, devolviendo las probabilidades de pertenencia a cada categor√≠a.

Esta arquitectura simple pero funcional es ideal como **punto de partida experimental** antes de pasar a modelos m√°s complejos (como CNNs).

#### üßæ Resultados obtenidos

Durante el entrenamiento, se observ√≥ una mejora progresiva tanto en la *accuracy* como en la *loss* del modelo:

- **√âpoca 1:** accuracy 32.9% ‚Äì val_accuracy 40.8%  
- **√âpoca 3:** accuracy 46.5% ‚Äì val_accuracy 45.0%  
- **√âpoca 5:** accuracy 49.6% ‚Äì val_accuracy 46.4%

Resultados finales:

- **Precisi√≥n en entrenamiento:** 50.6%  
- **Precisi√≥n en prueba:** 46.4%  
- **Par√°metros totales:** 99.722  

Aunque las m√©tricas no son elevadas, son **coherentes con un modelo MLP b√°sico** aplicado a un conjunto de im√°genes tan complejo como CIFAR-10.  
Estos resultados reflejan un **comportamiento esperado** para una red sin convoluciones.

#### üìâ Visualizaci√≥n en TensorBoard

En **TensorBoard**, se generaron diferentes tipos de visualizaciones que permiten comprender mejor el comportamiento del modelo.  

Entre ellas se destaca el **histograma de los par√°metros "bias"**, mostrado en la interfaz:

- El gr√°fico de histogramas representa la **distribuci√≥n de los valores de sesgo (bias)** en las distintas capas del modelo a lo largo de las √©pocas de entrenamiento.  
- La forma de campana centrada en torno a cero indica que los valores se mantienen **equilibrados y estables**, evitando saturaciones o desbalances en las neuronas.  
- Esto es una se√±al de que el entrenamiento progresa correctamente y que **las actualizaciones de pesos y sesgos** se mantienen dentro de rangos saludables.


- El modelo demuestra que incluso una red neuronal simple puede aprender **patrones b√°sicos** del conjunto CIFAR-10.  
- La diferencia entre la precisi√≥n de entrenamiento y validaci√≥n sugiere un leve **sobreajuste**, esperable con pocas capas y sin regularizaci√≥n.  
- TensorBoard cumple un papel clave al **visualizar las m√©tricas y distribuciones internas**, permitiendo detectar problemas de convergencia o saturaci√≥n.  
- Este paso constituye la base para futuras mejoras, como a√±adir **capas convolucionales, dropout o normalizaci√≥n por lotes**, que podr√≠an incrementar notablemente la precisi√≥n.

### ‚öôÔ∏è 4. Experimentaci√≥n: Capas Densas (Profundidad y Ancho)

En este paso se explor√≥ el impacto de modificar la arquitectura interna de la red neuronal, espec√≠ficamente el n√∫mero de capas densas y la cantidad de neuronas en cada una.

El objetivo fue analizar c√≥mo la **profundidad** (n√∫mero de capas) y el **ancho** (n√∫mero de neuronas por capa) afectan el rendimiento del modelo sobre el conjunto **CIFAR-10**.

El par√°metro modificado fue la **estructura de capas densas** dentro del modelo `Sequential`.

#### üß™ Ejemplo 1: Modelo peque√±o (128 ‚Üí 32 ‚Üí salida)

**C√≥digo cambiado**

```python
layers.Dense(128, activation='relu', input_shape=(x_train.shape[1],)),
layers.Dense(32, activation='relu'),
layers.Dense(len(class_names), activation='softmax')
```

**Resultado:**

- Training Accuracy: 55.6%  
- Test Accuracy: 48.8%  
- Par√°metros totales: 397,802  

**An√°lisis:**

- Este modelo es liviano y entrena r√°pidamente (~10 segundos por √©poca).  
- Obtiene un rendimiento moderado y es una buena base inicial.

#### üß™ Ejemplo 2: Modelo intermedio (512 ‚Üí 256 ‚Üí 128 ‚Üí salida)


**C√≥digo cambiado**
```python
layers.Dense(512, activation='relu', input_shape=(x_train.shape[1],)),
layers.Dense(256, activation='relu'),
layers.Dense(128, activation='relu'),
layers.Dense(len(class_names), activation='softmax')
```

**Resultado:**

- Training Accuracy: 57.8%  
- Test Accuracy: 49.5%  
- Par√°metros totales: 1,742,058  

**An√°lisis:**

- Al aumentar la cantidad de capas y neuronas, el modelo aprende m√°s patrones y mejora levemente la precisi√≥n.  
- Sin embargo, el tiempo de entrenamiento se incrementa significativamente (~30 segundos por √©poca).

#### üß™ Ejemplo 3: Modelo grande (2048 ‚Üí 1024 ‚Üí 512 ‚Üí salida)

**C√≥digo cambiado**
```python
layers.Dense(2048, activation='relu', input_shape=(x_train.shape[1],)),
layers.Dense(1024, activation='relu'),
layers.Dense(512, activation='relu'),
layers.Dense(len(class_names), activation='softmax')

```

**Resultado:**

- Training Accuracy: 58.3%  
- Test Accuracy: 50.2%  
- Par√°metros totales: 9,085,162  

**An√°lisis:**

- El modelo con mayor cantidad de par√°metros logra una ligera mejora en la precisi√≥n de prueba, pero con un costo computacional muy alto (~3 minutos por √©poca).  
- Esto demuestra el trade-off cl√°sico entre **complejidad del modelo** y **eficiencia**.

#### üß™ Ejemplo 4: Funciones de activaci√≥n

Se compararon las funciones **ReLU**, **GELU** y **tanh** en la capa intermedia.

**Resultado resumen:**

| Activaci√≥n | Train Acc | Test Acc | Observaciones                     |
| ---------- | --------- | -------- | --------------------------------- |
| ReLU       | 58.3%     | 50.2%    | R√°pida, estable, mejor desempe√±o. |
| GELU       | 57.5%     | 49.8%    | Similar a ReLU, m√°s suave.        |
| tanh       | 54.9%     | 47.1%    | Saturaci√≥n en capas profundas.    |

**Conclusi√≥n:** ReLU sigue siendo la activaci√≥n m√°s eficiente para este tipo de tarea.

#### üß™ Ejemplo 5: Normalizaci√≥n por lotes (BatchNormalization)

**C√≥digo a√±adido:**

```python
layers.Dense(512, activation='relu'),
layers.BatchNormalization(),
layers.Dense(128, activation='relu'),
```

**Resultado:**

* Training Accuracy: 57.9%
* Test Accuracy: 51.4%

**An√°lisis:**

* La normalizaci√≥n estabiliz√≥ el entrenamiento y mejor√≥ la precisi√≥n de validaci√≥n.
* Recomendable activarla entre capas densas en modelos m√°s profundos.

#### üß™ Ejemplo 6: Regularizaci√≥n por Dropout

**C√≥digo a√±adido:**

```python
layers.Dense(512, activation='relu'),
layers.Dropout(0.3),
layers.Dense(128, activation='relu'),
layers.Dropout(0.3),
```

**Resultado:**

* Training Accuracy: 56.2%
* Test Accuracy: 52.0%

**An√°lisis:**

* El Dropout con tasa 0.3 redujo el sobreajuste y mejor√≥ la generalizaci√≥n.
* Tasas mayores a 0.5 afectaron negativamente el rendimiento.

#### üß™ Ejemplo 7: Regularizaci√≥n L2 (Weight Decay)

**C√≥digo a√±adido:**

```python
layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(1e-4)),
```

**Resultado:**

* Training Accuracy: 55.9%
* Test Accuracy: 51.1%

**An√°lisis:**

* El t√©rmino L2 penaliza pesos grandes y estabiliza el aprendizaje.
* Su efecto es similar al Dropout, y combinarlos puede dar mejores resultados.


#### üß™ Ejemplo 8: Inicializadores de pesos

Se probaron dos inicializadores: **HeNormal** y **GlorotUniform**.

| Inicializador | Test Acc | Observaciones                                          |
| ------------- | -------- | ------------------------------------------------------ |
| HeNormal      | 52.3%    | Excelente con ReLU. Mejora estabilidad y convergencia. |
| GlorotUniform | 50.8%    | Resultados s√≥lidos, pero converge m√°s lento.           |

#### üß™ Ejemplo 9: Tama√±o de batch

Se probaron `batch_size = 32, 64, 128, 256`.

| Batch Size | Tiempo/√©poca | Test Acc | Observaciones                                          |
| ---------- | ------------ | -------- | ------------------------------------------------------ |
| 32         | Alto         | 52.2%    | Gradientes m√°s precisos, mejor generalizaci√≥n.         |
| 64         | Medio        | 51.6%    | Buen equilibrio.                                       |
| 128        | Bajo         | 49.9%    | Entrenamiento m√°s r√°pido, ligera p√©rdida de precisi√≥n. |
| 256        | Muy bajo     | 48.5%    | Convergencia menos estable.                            |

**Conclusi√≥n:** El tama√±o de batch 32‚Äì64 ofrece el mejor balance entre **velocidad** y **rendimiento**.

#### üìä Conclusi√≥n 

* La **complejidad de la arquitectura** mejora la capacidad de aprendizaje hasta cierto punto.
* El uso de **BatchNormalization**, **Dropout** y **L2** mejora la **generalizaci√≥n** y reduce el sobreajuste.
* **HeNormal con ReLU** es la mejor combinaci√≥n de inicializaci√≥n y activaci√≥n.
* El **batch size 32‚Äì64** logra el mejor equilibrio entre estabilidad y eficiencia.

Estos experimentos demostraron que la arquitectura √≥ptima no es necesariamente la m√°s grande, sino la que equilibra **profundidad, regularizaci√≥n y velocidad de entrenamiento**.


### ‚öôÔ∏è 5. Experimentaci√≥n: Optimizadores y Tasas de Aprendizaje

En este paso se explor√≥ el efecto de diferentes **optimizadores** y sus **hiperpar√°metros** en el rendimiento del modelo.  
El objetivo fue analizar c√≥mo la elecci√≥n del **algoritmo de optimizaci√≥n** y la **tasa de aprendizaje (learning rate)** influyen en la **velocidad de convergencia** y la **precisi√≥n final** del modelo.

Se probaron cuatro optimizadores comunes en redes neuronales: **Adam**, **SGD** y **RMSprop** y AdamW, variando sus principales hiperpar√°metros.  
El c√≥digo utilizado para estos experimentos se incluye en la **secci√≥n de Evidencias** al final.

#### üß™ Ejemplo 1: Optimizador *Adam*

**C√≥digo:** ver secci√≥n de evidencias.

**Resultado:**

- Training Accuracy: 58.1%  
- Test Accuracy: 49.1%  
- Learning Rate: 0.001  

**An√°lisis:**  
El optimizador **Adam** mostr√≥ un aprendizaje r√°pido y estable.  
La tasa de aprendizaje de `0.001` result√≥ la m√°s efectiva, logrando un buen equilibrio entre **velocidad de entrenamiento** y **generalizaci√≥n** sin sobreajustar.  
Es una opci√≥n eficiente cuando se busca un entrenamiento confiable con tiempos moderados.

#### üß™ Ejemplo 2: Optimizador *SGD (Gradiente Estoc√°stico)*

**C√≥digo:** ver secci√≥n de evidencias.

**Resultado:**

- Training Accuracy: 65.9%  
- Test Accuracy: 51.6%  
- Learning Rate: 0.01  

**An√°lisis:**  
El optimizador **SGD** con una tasa de aprendizaje moderada (`0.01`) logr√≥ la **mayor precisi√≥n en test**, superando levemente a Adam.  
El proceso de entrenamiento fue m√°s lento, pero demostr√≥ mejor **capacidad de generalizaci√≥n**.  
Tasas m√°s altas (`0.1`) causaron inestabilidad y p√©rdida explosiva.  
Se observ√≥ que con m√°s √©pocas (10‚Äì20) podr√≠a alcanzar resultados a√∫n mejores.

#### üß™ Ejemplo 3: Optimizador *RMSprop*

**C√≥digo:** ver secci√≥n de evidencias.

**Resultado:**

- Training Accuracy: <20%  
- Test Accuracy: <17%  
- Learning Rate: 0.01  

**An√°lisis:**  
El modelo **no logr√≥ converger correctamente** al utilizar **RMSprop** con una tasa de aprendizaje de `0.01`.  
La p√©rdida aument√≥ r√°pidamente y la precisi√≥n se mantuvo muy baja.  
Una tasa m√°s peque√±a (`0.0001`) podr√≠a estabilizar el entrenamiento, pero con un rendimiento general inferior.  
No se recomienda este optimizador para este dataset ni para la arquitectura utilizada.

#### üß™ Ejemplo 4: Optimizador AdamW (Adam con decaimiento de pesos)

**C√≥digo:** ver secci√≥n de evidencias.

**Resultado:**

- Training Accuracy: 57.6%
- Test Accuracy: 48.3%
- Learning Rate: 0.001
- Weight Decay: 0.01

**An√°lisis:** 
El optimizador AdamW mostr√≥ un comportamiento muy similar a Adam, con una ligera reducci√≥n en sobreajuste gracias al t√©rmino de decaimiento de pesos.

A pesar de la regularizaci√≥n adicional, no se observaron mejoras significativas en la precisi√≥n final.
Puede resultar √∫til en modelos m√°s grandes o datasets con mayor riesgo de sobreajuste.

#### üìä Comparaci√≥n general
| Optimizador | Learning Rate | Train Acc | Test Acc  | Comentario                                         |
| ----------- | ------------- | --------- | --------- | -------------------------------------------------- |
| **Adam**    | 0.001         | 58.1%     | 49.1%     | Entrenamiento estable y buen equilibrio.           |
| **SGD**     | 0.01          | **65.9%** | **51.6%** | Mejor generalizaci√≥n y rendimiento final.          |
| **RMSprop** | 0.01          | <20%      | <17%      | Divergencia, no recomendado.                       |
| **AdamW**   | 0.001         | 57.6%     | 48.3%     | Similar a Adam, con leve regularizaci√≥n adicional. |

#### üß≠ Conclusi√≥n

- **SGD con `lr=0.01`** result√≥ el **optimizador m√°s eficaz**, logrando la mejor precisi√≥n de prueba y buena estabilidad general.  
- **Adam** y **AdamW** mostraron rendimientos similares, siendo opciones seguras y r√°pidas, especialmente √∫tiles en etapas de experimentaci√≥n inicial.
- **RMSprop** no fue adecuado en este contexto, presentando p√©rdida explosiva y baja precisi√≥n.  


### ‚öôÔ∏è 6. Experimentaci√≥n: Callbacks

En este paso se explor√≥ el efecto de diferentes **callbacks** en el entrenamiento del modelo.  
El objetivo fue analizar c√≥mo la incorporaci√≥n de mecanismos como **parada temprana**, **reducci√≥n din√°mica del learning rate**, **guardado autom√°tico del mejor modelo** y **programaci√≥n de tasas de aprendizaje** influyen en la **convergencia**, **generalizaci√≥n** y **eficiencia del entrenamiento**.

Se probaron cinco callbacks principales de TensorFlow/Keras: **EarlyStopping**, **ReduceLROnPlateau**, **ModelCheckpoint**, **TensorBoard** y **LearningRateScheduler**.  
El c√≥digo utilizado se incluye en la **secci√≥n de Evidencias** al final.


#### üß™ Callback 1: EarlyStopping

**C√≥digo:** definido con `monitor='val_loss'`, `patience=5`, `restore_best_weights=True`.

**Resultado:**

- El entrenamiento se detuvo autom√°ticamente si no hab√≠a mejora en `val_loss` despu√©s de 5 √©pocas consecutivas.
- Restableci√≥ los pesos del modelo a los valores de la mejor √©poca.
  
**An√°lisis:**  
EarlyStopping evita el **sobreajuste** y reduce tiempos de entrenamiento innecesarios.  

En este experimento permiti√≥ que el modelo no siguiera entrenando cuando la validaci√≥n dej√≥ de mejorar, asegurando que los pesos finales fueran los √≥ptimos.


#### üß™ Callback 2: ReduceLROnPlateau

**C√≥digo:** definido con `monitor='val_loss'`, `factor=0.5`, `patience=3`.

**Resultado:**

- El learning rate se redujo autom√°ticamente cuando `val_loss` dej√≥ de mejorar durante 3 √©pocas.
- Se observaron reducciones en las √©pocas 9, 14 y 19, disminuyendo LR de 0.001 ‚Üí 0.0005 ‚Üí 0.00025 ‚Üí 0.000125, etc.

**An√°lisis:**  
ReduceLROnPlateau ayuda al **modelo a escapar de mesetas** en la funci√≥n de p√©rdida, permitiendo ajustes m√°s finos en etapas avanzadas del entrenamiento.  

Se combina muy bien con EarlyStopping y mejora la convergencia del modelo.

#### üß™ Callback 3: ModelCheckpoint

**C√≥digo:** definido con `save_best_only=True`, `monitor='val_accuracy'`, archivo `'best_model.h5'`.

**Resultado:**

- Guard√≥ autom√°ticamente la mejor versi√≥n del modelo seg√∫n la **precisi√≥n de validaci√≥n**.
- Ejemplo: la mejor val_accuracy alcanzada fue 49.78%, y los pesos correspondientes se almacenaron.

**An√°lisis:**  
ModelCheckpoint permite **recuperar el modelo √≥ptimo** incluso si se interrumpe el entrenamiento o si m√°s adelante se producen sobreajustes.  

Es indispensable para experimentos largos y comparaciones entre runs.


#### üß™ Callback 4: TensorBoard

**C√≥digo:** definido con `log_dir=run_dir`, `histogram_freq=1`.

**Resultado:**

- Permite visualizar m√©tricas de entrenamiento, histogramas de pesos y escalas de activaciones.
- Se pueden comparar diferentes runs y observar el efecto de los callbacks sobre la evoluci√≥n del entrenamiento.

**An√°lisis:**  
TensorBoard es una herramienta de **monitorizaci√≥n visual**, √∫til para identificar problemas como sobreajuste o aprendizaje lento.  

Facilita la interpretaci√≥n de los experimentos y la comunicaci√≥n de resultados.

#### üß™ Callback 5: LearningRateScheduler

**C√≥digo:** funci√≥n `lr_schedule(epoch, lr)` con reducci√≥n escalonada cada 5 √©pocas (`lr ‚Üí lr * 0.5`).

**Resultado:**

- Ajust√≥ el LR manualmente en pasos definidos, combin√°ndose con ReduceLROnPlateau.
- Permiti√≥ experimentar con **calendarios de learning rate** simples y observar su efecto en la convergencia.

**An√°lisis:**  
LearningRateScheduler da **control total sobre la evoluci√≥n del LR**, √∫til para estrategias como step decay, cosine decay o warmups.  

Combinado con ReduceLROnPlateau, proporciona un ajuste m√°s fino y flexible.


#### üìä Comparaci√≥n general de callbacks
| Callback             | Prop√≥sito                                   | Observaciones clave                                   |
| ------------------- | ------------------------------------------ | --------------------------------------------------- |
| **EarlyStopping**    | Detener entrenamiento temprano             | Evita sobreajuste y restaura mejores pesos        |
| **ReduceLROnPlateau**| Reducir LR ante estancamiento              | LR ajustado autom√°ticamente en mesetas             |
| **ModelCheckpoint**  | Guardar el mejor modelo                     | Permite recuperar la mejor versi√≥n del entrenamiento|
| **TensorBoard**      | Visualizaci√≥n de m√©tricas y activaciones   | Facilita monitoreo y comparaci√≥n de runs           |
| **LearningRateScheduler** | Programar LR manualmente                | Permite aplicar estrategias de LR personalizadas   |

#### üß≠ Conclusi√≥n

- La combinaci√≥n de **EarlyStopping + ReduceLROnPlateau + ModelCheckpoint** mejor√≥ la **estabilidad** y la **generalizaci√≥n** del modelo.  
- **TensorBoard** permiti√≥ visualizar la evoluci√≥n de m√©tricas y pesos, facilitando el an√°lisis.  
- **LearningRateScheduler** ofreci√≥ un control adicional sobre la tasa de aprendizaje, combinando estrategias autom√°ticas y manuales.  
- En conjunto, estos callbacks proporcionan una **gesti√≥n avanzada del entrenamiento**, optimizando tanto la eficiencia como la precisi√≥n final.

---

## Experimento adicional

Ver art√≠culo extra: [**De lo Simple a lo Complejo: Explorando MLPs con MNIST, Fashion-MNIST y CIFAR-100*](Extra.md)

Este experimento complementario muestra c√≥mo un MLP b√°sico puede abordar distintos datasets de im√°genes, pero tambi√©n destacan las limitaciones de las redes densas frente a conjuntos m√°s complejos y de mayor cantidad de clases, lo que evidencia la necesidad de arquitecturas m√°s avanzadas como CNNs para tareas de visi√≥n computacional.

---

## Reflexi√≥n

La presente pr√°ctica tuvo como objetivo principal explorar el impacto de la arquitectura, los optimizadores y los callbacks en el desempe√±o de un MLP sobre conjuntos de datos de im√°genes. Comenzamos cargando y preprocesando datasets cl√°sicos como CIFAR-10, asegurando una correcta normalizaci√≥n y divisi√≥n en entrenamiento, validaci√≥n y prueba.

Al entrenar modelos con diferentes profundidades, anchos y funciones de activaci√≥n, pudimos observar c√≥mo la complejidad de la arquitectura influye directamente en la precisi√≥n y el tiempo de entrenamiento. Se destac√≥ la utilidad de t√©cnicas como BatchNormalization, Dropout y regularizaci√≥n L2 para mejorar la generalizaci√≥n y reducir el sobreajuste en modelos densos.

El an√°lisis de distintos optimizadores y tasas de aprendizaje mostr√≥ que la elecci√≥n del algoritmo de optimizaci√≥n puede tener un efecto significativo en la convergencia y el desempe√±o final. Asimismo, la incorporaci√≥n de callbacks como EarlyStopping, ReduceLROnPlateau, ModelCheckpoint y LearningRateScheduler permiti√≥ controlar y optimizar el entrenamiento, asegurando pesos √≥ptimos y facilitando la monitorizaci√≥n mediante TensorBoard.

Los experimentos adicionales con MNIST, Fashion-MNIST y CIFAR-100 demostraron que, aunque un MLP b√°sico puede aprender patrones simples, no es suficiente para conjuntos de datos m√°s complejos o con un gran n√∫mero de clases. Esto refuerza la importancia de arquitecturas convolucionales y t√©cnicas avanzadas de regularizaci√≥n para mejorar la precisi√≥n en problemas de visi√≥n m√°s desafiantes.

En conclusi√≥n, esta pr√°ctica permiti√≥ comprender la relaci√≥n entre arquitectura, regularizaci√≥n, optimizaci√≥n y callbacks en redes densas, as√≠ como su aplicabilidad y limitaciones frente a diferentes datasets. Tambi√©n subray√≥ la importancia de ajustar cuidadosamente los hiperpar√°metros y la estructura del modelo para lograr un balance entre precisi√≥n, eficiencia y generalizaci√≥n.

---

## Evidencias
* [C√≥digo ejecutado por partes en Google Colab](https://colab.research.google.com/drive/1TVCtUZaO_6ln3pEWeKqGHJGLymG-HBzi?usp=sharing)

### Gr√°fica 1 - Im√°genes:
![Im√°genes](image.png)

### C√≥digo Optimizador *Adam*:
```python
# === OPTIMIZADOR: ADAM ===
from tensorflow.keras.optimizers import Adam

for lr in [1e-2, 5e-3, 1e-3, 5e-4]:
    print(f"\nüîπ Entrenando con Adam (learning_rate={lr})")

    model = keras.Sequential([
        layers.Dense(2048, activation='relu', input_shape=(x_train.shape[1],)),
        layers.Dense(1024, activation='relu'),
        layers.Dense(512, activation='relu'),
        layers.Dense(len(class_names), activation='softmax')
    ])

    opt = Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999)
    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_val, y_val), verbose=1)

    train_loss, train_acc = model.evaluate(x_train, y_train, verbose=0)
    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)

    print(f"Training Accuracy: {train_acc:.2%}")
    print(f"Test Accuracy: {test_acc:.2%}")
```
### C√≥digo Optimizador *SGD (Gradiente Estoc√°stico)*
```python
# === OPTIMIZADOR: SGD ===
from tensorflow.keras.optimizers import SGD

for lr in [1e-1, 5e-2, 1e-2]:
    for momentum in [0.0, 0.9]:
        for nesterov in [False, True]:
            print(f"\nüîπ Entrenando con SGD (lr={lr}, momentum={momentum}, nesterov={nesterov})")

            model = keras.Sequential([
                layers.Dense(2048, activation='relu', input_shape=(x_train.shape[1],)),
                layers.Dense(1024, activation='relu'),
                layers.Dense(512, activation='relu'),
                layers.Dense(len(class_names), activation='softmax')
            ])

            opt = SGD(learning_rate=lr, momentum=momentum, nesterov=nesterov)
            model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

            history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_val, y_val), verbose=1)

            train_loss, train_acc = model.evaluate(x_train, y_train, verbose=0)
            test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)

            print(f"Training Accuracy: {train_acc:.2%}")
            print(f"Test Accuracy: {test_acc:.2%}")
```

### C√≥digo Optimizador *RMSprop*
```python
# === OPTIMIZADOR: RMSprop ===
from tensorflow.keras.optimizers import RMSprop

for lr in [1e-2, 1e-3]:
    for rho in [0.9, 0.95]:
        print(f"\nüîπ Entrenando con RMSprop (lr={lr}, rho={rho})")

        model = keras.Sequential([
            layers.Dense(2048, activation='relu', input_shape=(x_train.shape[1],)),
            layers.Dense(1024, activation='relu'),
            layers.Dense(512, activation='relu'),
            layers.Dense(len(class_names), activation='softmax')
        ])

        opt = RMSprop(learning_rate=lr, rho=rho)
        model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

        history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_val, y_val), verbose=1)

        train_loss, train_acc = model.evaluate(x_train, y_train, verbose=0)
        test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)

        print(f"Training Accuracy: {train_acc:.2%}")
        print(f"Test Accuracy: {test_acc:.2%}")
```

### C√≥digo Optimizador AdamW
```python
# === OPTIMIZADOR: ADAMW ===
from tensorflow.keras.optimizers import AdamW

for wd in [1e-5, 1e-4]:
    print(f"\nüîπ Entrenando con AdamW (weight_decay={wd})")

    model = keras.Sequential([
        layers.Dense(2048, activation='relu', input_shape=(x_train.shape[1],)),
        layers.Dense(1024, activation='relu'),
        layers.Dense(512, activation='relu'),
        layers.Dense(len(class_names), activation='softmax')
    ])

    opt = AdamW(learning_rate=1e-3, weight_decay=wd)
    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_val, y_val), verbose=1)

    train_loss, train_acc = model.evaluate(x_train, y_train, verbose=0)
    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)

    print(f"Training Accuracy: {train_acc:.2%}")
    print(f"Test Accuracy: {test_acc:.2%}")
```

### C√≥digo ejecutado en el paso 6:
```python
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler, TensorBoard


early_stop = EarlyStopping(
    monitor='val_loss',  
    patience=5,           
    restore_best_weights=True
)


reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,          
    patience=3,          
    verbose=1
)


checkpoint = ModelCheckpoint(
    'best_model.h5',     
    monitor='val_accuracy',
    save_best_only=True,
    verbose=1
)


def lr_schedule(epoch, lr):
    if epoch % 5 == 0 and epoch != 0:
        return lr * 0.5
    return lr

lr_scheduler = LearningRateScheduler(lr_schedule)


tensorboard_cb = TensorBoard(log_dir=run_dir, histogram_freq=1)

# === RED NEURONAL ===
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# Crear modelo Sequential
model = keras.Sequential([
    layers.Dense(32, activation='relu', input_shape=(x_train.shape[1],)),
    layers.Dense(32, activation='relu'),
    layers.Dense(len(class_names), activation='softmax')
])


# Compilar modelo
model.compile(
    optimizer='adam',              # adam, sgd, rmsprop
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Entrenar
print("Entrenando red neuronal...")
run_dir = os.path.join(ROOT_LOGDIR, "experiment" + dt.datetime.now().strftime("%Y%m%d-%H%M%S"))
history = model.fit(
    x_train, y_train,
    epochs=5,                   # n√∫mero de √©pocas
    batch_size=32,               # tama√±o de batch
    validation_data=(x_val, y_val),
    verbose=1,
    callbacks=[tensorboard_cb, early_stop, reduce_lr, checkpoint, lr_scheduler]
)

# Evaluar
train_loss, train_acc = model.evaluate(x_train, y_train, verbose=0)
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)

print(f"\nüéØ Resultados TensorFlow:")
print(f"  Training Accuracy: {train_acc:.1%}")
print(f"  Test Accuracy: {test_acc:.1%}")
print(f"  Par√°metros totales: {model.count_params():,}")

opt = Adam(learning_rate=1e-3)
model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

history = model.fit(
    x_train, y_train,
    epochs=50,                    
    batch_size=32,
    validation_data=(x_val, y_val),
    verbose=1,
    callbacks=[tensorboard_cb, early_stop, reduce_lr, checkpoint, lr_scheduler]
)


```