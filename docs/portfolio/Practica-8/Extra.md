# De lo Simple a lo Complejo: Explorando MLPs con MNIST, Fashion-MNIST y CIFAR-100

## Contexto

En este experimento se busc贸 evaluar el rendimiento de un MLP b谩sico frente a datasets de complejidad creciente: desde d铆gitos manuscritos (MNIST), hasta ropa (Fashion-MNIST) y finalmente im谩genes de 100 clases (CIFAR-100).

El objetivo fue comprender las capacidades y limitaciones de las redes densas al enfrentarse a problemas m谩s complejos y observar c贸mo var铆a la precisi贸n seg煤n la naturaleza del dataset.

---

##  Objetivos

- Analizar el desempe帽o de un MLP simple en distintos conjuntos de datos de im谩genes.
- Observar la relaci贸n entre complejidad del dataset, profundidad del modelo y precisi贸n de entrenamiento y prueba.
- Destacar la necesidad de arquitecturas avanzadas (CNNs) para datasets complejos como CIFAR-100.

---

## Actividades

| Actividad                                      | Resultado esperado                                                                                                                         |
| ---------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------ |
| **1. MNIST: Clasificaci贸n de d铆gitos**         | El MLP b谩sico logra alta precisi贸n (>94%) tanto en entrenamiento como en prueba. Diferencia m铆nima indica bajo sobreajuste.                |
| **2. Fashion-MNIST: Clasificaci贸n de prendas** | El MLP obtiene precisi贸n moderada (~86% test), mostrando mayor dificultad que MNIST debido a formas similares y clases m谩s complejas.      |
| **3. CIFAR-100: Clasificaci贸n de 100 clases**  | El MLP logra baja precisi贸n (~19% test), evidenciando la insuficiencia de redes densas para datasets complejos. Se recomienda usar CNNs.   |
| **4. Visualizaci贸n de im谩genes**               | Todas las im谩genes de cada dataset se muestran correctamente en sus respectivas secciones de evidencias.                                   |
| **5. Comparaci贸n de resultados**               | Tabla comparativa con precisi贸n de entrenamiento y prueba que permite ver claramente el efecto de la complejidad del dataset sobre el MLP. |

---

## Desarrollo:

### И Paso 1: MNIST

**C贸digo cambiado:**

```python
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
class_names = [str(i) for i in range(10)]
```

**Resultado:**

```
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11490434/11490434  0s 0us/step
Train: (54000, 784) Val: (6000, 784) Test: (10000, 784)
```

**C贸digo cambiado para visualizar im谩genes:**

```python
ax.imshow((x_train[i].reshape(28,28)/2 + 0.5).clip(0,1), cmap='gray')
```

**Resultado:**
Las im谩genes se muestran en la secci贸n de evidencias.

**C贸digo cambiado para entrenar el modelo:**

```python
layers.Dense(32, activation='relu', input_shape=(x_train.shape[1],)),
layers.Dense(32, activation='relu'),
layers.Dense(len(class_names), activation='softmax')
```

**Resultado:**

```
Entrenando red neuronal...
Epoch 1/5 ... val_accuracy: 0.9257 ...
Epoch 5/5 ... val_accuracy: 0.9463
 Resultados TensorFlow:
  Training Accuracy: 94.8%
  Test Accuracy: 94.1%
  Par谩metros totales: 26,506
```
#### An谩lisis:

El modelo MLP logra un rendimiento excelente sobre MNIST, dataset relativamente simple y con pocas clases (10).

La diferencia m铆nima entre entrenamiento y test indica bajo sobreajuste.

La arquitectura b谩sica (2 capas de 32 neuronas) es suficiente para alcanzar >94% de precisi贸n.

### И Paso 2: Fashion-MNIST

**C贸digo cambiado:**

```python
(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()
class_names = ['T-shirt/top','Trouser','Pullover','Dress','Coat',
               'Sandal','Shirt','Sneaker','Bag','Ankle boot']
```

**Resultado:**

```
Downloading data from ...
Train: (54000, 784) Val: (6000, 784) Test: (10000, 784)
```

**C贸digo para visualizar im谩genes:**

```python
ax.imshow((x_train[i].reshape(28,28)/2 + 0.5).clip(0,1), cmap='gray')
```

**Resultado:**
Las im谩genes se encuentran en la secci贸n de evidencias.

**C贸digo cambiado al entrenar:**

```python
layers.Dense(32, activation='relu', input_shape=(x_train.shape[1],)),
layers.Dense(32, activation='relu'),
layers.Dense(len(class_names), activation='softmax')
```

**Resultado:**

```
Entrenando red neuronal...
Epoch 5/5 ... val_accuracy: 0.8732
 Resultados TensorFlow:
  Training Accuracy: 88.5%
  Test Accuracy: 86.0%
  Par谩metros totales: 26,506
```

#### An谩lisis:

Fashion-MNIST es m谩s complejo que MNIST debido a formas m谩s sutiles y clases de ropa similares.

La precisi贸n cae ~8 puntos respecto a MNIST, lo que refleja la mayor dificultad del dataset.

Todav铆a hay un buen balance entre entrenamiento y test, aunque un MLP m谩s profundo o regularizado podr铆a mejorar la generalizaci贸n.

### И Paso 3: CIFAR-100

**C贸digo cambiado:**

```python
(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()
class_names = [str(i) for i in range(100)]
```

**Resultado:**

```
Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz
169001437/169001437  135s 1us/step
Train: (45000, 3072) Val: (5000, 3072) Test: (10000, 3072)
```

**C贸digo para visualizar im谩genes:**

```python
ax.imshow((x_train[i].reshape(32,32,3)/2 + 0.5).clip(0,1))
ax.set_title(class_names[y_train[i]])
```

**Resultado:**
Las im谩genes se encuentran en la secci贸n de evidencias.

**C贸digo cambiado al entrenar:**

```python
layers.Dense(512, activation='relu', input_shape=(x_train.shape[1],)),
layers.Dense(256, activation='relu'),
layers.Dense(128, activation='relu'),
layers.Dense(len(class_names), activation='softmax')
```

**Resultado:**

```
Entrenando red neuronal...
Epoch 5/5 ... val_accuracy: 0.1786
 Resultados TensorFlow:
  Training Accuracy: 24.8%
  Test Accuracy: 18.7%
  Par谩metros totales: 1,750,500
```
#### An谩lisis:

CIFAR-100 es un dataset mucho m谩s desafiante: 32x32x3 im谩genes, 100 clases, con alta variabilidad de color y forma.

El MLP simple no es adecuado: el modelo alcanza solo ~19% de precisi贸n en test.

Se observa sobreajuste leve (training 25%, test 19%) a pesar de la gran cantidad de par谩metros.

Para este tipo de datos se recomienda usar redes convolucionales (CNN) que puedan capturar relaciones espaciales en im谩genes.

#### Tabla comparativa:
| Dataset       | Clases | Train Acc | Test Acc | Observaciones                                         |
| ------------- | ------ | --------- | -------- | ----------------------------------------------------- |
| MNIST         | 10     | 94.8%     | 94.1%    | Dataset simple, MLP b谩sico funciona muy bien          |
| Fashion-MNIST | 10     | 88.5%     | 86.0%    | Dataset m谩s complejo, MLP a煤n aceptable               |
| CIFAR-100     | 100    | 24.8%     | 18.7%    | Dataset complejo, MLP insuficiente, se recomienda CNN |

---

## Reflexi贸n

Este experimento permiti贸 observar claramente la relaci贸n entre la complejidad del dataset y la efectividad de un MLP b谩sico.

MNIST: un dataset simple, con pocas clases y alta linealidad, demuestra que un MLP con 2 capas de 32 neuronas es suficiente para lograr >94% de precisi贸n.

Fashion-MNIST: con clases m谩s parecidas y patrones m谩s complejos, el mismo MLP mantiene un desempe帽o aceptable (~86%), pero se evidencia que modelos m谩s profundos o regularizados podr铆an mejorar la generalizaci贸n.

CIFAR-100: la gran cantidad de clases y la complejidad espacial y crom谩tica de las im谩genes muestran que un MLP simple es insuficiente; se requiere una arquitectura convolucional para capturar las relaciones espaciales en las im谩genes y mejorar la precisi贸n.

En conclusi贸n, este experimento refuerza la idea de que la elecci贸n de la arquitectura debe estar alineada con la complejidad del problema. Los MLPs funcionan muy bien en problemas simples, pero para tareas de visi贸n m谩s complejas se deben usar CNNs u otras arquitecturas avanzadas, combinadas con t茅cnicas de regularizaci贸n y preprocesamiento adecuado.

---

## Evidencias
* [C贸digo ejecutado por partes en Google Colab](https://colab.research.google.com/drive/1bDZhH7MZasskY83IhvxPR3qL9pxSSbq6?usp=sharing)

### Gr谩fica 1 - MNIST:
![MNIST](image1.png)

### Gr谩fica 2 - Fashion-MNIST:
![Fashion-MNIST](image2.png)

### Gr谩fica 3 - CIFAR-100:
![CIFAR-100](image3.png)

