#  Explorando las limitaciones del Perceptr贸n: C铆rculos Conc茅ntricos y Fronteras No Lineales

> En este experimento analizamos c贸mo un perceptr贸n simple fracasa al intentar separar datos no lineales, utilizando el dataset de c铆rculos conc茅ntricos. Este caso ilustra la necesidad de redes neuronales multicapa (MLP).

En este paso, experimentamos con el dataset de c铆rculos conc茅ntricos generado por make_circles() de Scikit-Learn. Este conjunto de datos es 煤til para comprender c贸mo un perceptr贸n b谩sico maneja datos no linealmente separables. El dataset consiste en dos clases organizadas en c铆rculos conc茅ntricos, lo que implica que no pueden ser separadas por una simple l铆nea recta.

#### Generaci贸n y Visualizaci贸n del Dataset:

* Primero, generamos y visualizamos los datos en dos dimensiones, donde las caracter铆sticas **Feature 1** y **Feature 2** se representan en un gr谩fico de dispersi贸n. Las clases est谩n representadas por puntos rojos y azules. Como resultado, observamos que los puntos de la **Clase 0** y **Clase 1** se distribuyen en c铆rculos conc茅ntricos.

* A continuaci贸n, entrenamos un **perceptr贸n b谩sico** para clasificar este conjunto de datos. Dado que los c铆rculos conc茅ntricos no son linealmente separables, el perceptr贸n enfrenta dificultades para encontrar una soluci贸n que separe correctamente las dos clases.

* Para comprender mejor el comportamiento del perceptr贸n, graficamos su **frontera de decisi贸n**, lo que nos permite visualizar c贸mo clasifica el espacio de caracter铆sticas. Aunque el perceptr贸n intenta trazar una l铆nea de separaci贸n, la frontera generada no divide correctamente las dos clases.

#### Resultado obtenido:

Las gr谩ficas se encuentran en evidencias. 

* La imagen muestra claramente los dos grupos de puntos distribuidos de manera circular, con los puntos de la **Clase 0** (rojos) en el centro y los de la **Clase 1** (azules) en el borde exterior.

* El **perceptr贸n** obtiene una **precisi贸n de 0.4000**, lo que indica que el modelo est谩 fallando en clasificar correctamente las dos clases. Como era de esperar, debido a que el problema no es linealmente separable, el perceptr贸n no puede generar una correcta frontera de decisi贸n utilizando solo una capa.

* La **frontera de decisi贸n** del perceptr贸n es claramente visible en el gr谩fico. Aunque el modelo intenta generar una separaci贸n, la l铆nea trazada no refleja una correcta divisi贸n de las clases. El 谩rea verde y morada indica que el modelo no logra separar adecuadamente los puntos de las dos clases, lo que confirma las limitaciones del perceptr贸n para resolver este problema no lineal.


Este experimento destaca c贸mo el **perceptr贸n b谩sico** enfrenta serias dificultades al tratar de resolver datasets no linealmente separables, como el caso de los c铆rculos conc茅ntricos. A pesar de que el modelo realiza una clasificaci贸n aproximada, su **precisi贸n de solo 40%** evidencia que un perceptr贸n simple no es adecuado para problemas de clasificaci贸n complejos.

La visualizaci贸n de la **frontera de decisi贸n** subraya que, aunque el perceptr贸n intenta generar una separaci贸n, no puede manejar la complejidad inherente al problema. Esto demuestra la necesidad de redes neuronales m谩s sofisticadas, como las redes **MLP (Multi-Layer Perceptron)**, que pueden manejar problemas no lineales mediante capas ocultas.

Este resultado marca el punto de partida hacia arquitecturas m谩s complejas, como las redes MLP, capaces de modelar relaciones no lineales y resolver este tipo de problemas con precisi贸n mucho mayor.



---
## Evidencias
* [C贸digo ejecutado por partes en Google Colab](https://colab.research.google.com/drive/1B0b8fH3DJB6KTvSEe_C2nEhoPJp-ImGx?usp=sharing)

### Gr谩fica 1 - Dataset: C铆rculos Conc茅ntricos:
![Dataset: C铆rculos Conc茅ntricos](image8.png)

### Gr谩fica 2 - Perceptr贸n en C铆rculos Conc茅ntricos:
![Perceptr贸n en C铆rculos Conc茅ntricos](image9.png)

### C贸digo completo:

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_circles
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
# Generar el dataset de c铆rculos conc茅ntricos
X, y = make_circles(n_samples=100, noise=0.1, factor=0.5)

# Visualizar los datos
plt.figure(figsize=(6,6))
plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], color='red', label='Clase 0')
plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], color='blue', label='Clase 1')
plt.title('Dataset: C铆rculos Conc茅ntricos')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.show()
# Dividir en datos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Crear y entrenar el perceptr贸n
clf = MLPClassifier(hidden_layer_sizes=(), activation='relu', max_iter=1000)
clf.fit(X_train, y_train)

# Evaluar el modelo
accuracy = clf.score(X_test, y_test)
print(f'Precisi贸n del Perceptr贸n: {accuracy:.4f}')
# Graficar la frontera de decisi贸n
xx, yy = np.meshgrid(np.linspace(X[:, 0].min(), X[:, 0].max(), 100), 
                     np.linspace(X[:, 1].min(), X[:, 1].max(), 100))
Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

# Visualizar
plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.brg)
plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], color='red', label='Clase 0')
plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], color='blue', label='Clase 1')
plt.title('Perceptr贸n en C铆rculos Conc茅ntricos')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.legend()
plt.show()

```