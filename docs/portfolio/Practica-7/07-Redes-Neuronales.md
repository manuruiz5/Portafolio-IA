# üìù **Del perceptr√≥n al aprendizaje profundo: c√≥mo las redes neuronales superan los l√≠mites lineales**

## Contexto

El objetivo de esta pr√°ctica es comprender c√≥mo un perceptr√≥n b√°sico evoluciona hacia redes neuronales m√°s complejas y c√≥mo estas redes pueden resolver problemas de clasificaci√≥n m√°s dif√≠ciles. Comenzaremos con los conceptos fundamentales detr√°s del **perceptr√≥n**, un modelo de clasificaci√≥n binaria, para luego abordar problemas m√°s complejos como el **XOR**, y finalmente, implementaremos **redes neuronales multicapa (MLP)** para superar las limitaciones del perceptr√≥n.

El dataset ser√° utilizado para demostrar c√≥mo las redes neuronales pueden aprender patrones no lineales, desde problemas l√≥gicos simples (como **AND**, **OR**, **NOT**) hasta problemas m√°s complejos, como **XOR**.

---

## üéØ Objetivos

- Entender las **limitaciones del perceptr√≥n b√°sico** y c√≥mo resuelve problemas como **AND**, **OR** y **NOT**.
- Abordar el problema cl√°sico **XOR**, y explorar por qu√© un perceptr√≥n simple no puede resolverlo.
- Implementar una **red neuronal multicapa (MLP)** para resolver el problema **XOR**.
- Visualizar el comportamiento de **redes neuronales multicapa** y su capacidad para separar datos no lineales.
- Comparar los resultados utilizando diferentes **frameworks** (Scikit-learn, TensorFlow y PyTorch Lightning).

---
## Marco Te√≥rico

### **Redes Neuronales Artificiales**

Las **redes neuronales artificiales** son modelos de aprendizaje inspirados en el sistema nervioso de los seres vivos. Se componen de unidades llamadas **neuronas artificiales** que adoptan valores y est√°n conectadas por **sinapsis** que tienen asociados **pesos**. Cada neurona procesa las se√±ales recibidas a trav√©s de las conexiones y genera una salida modificada por una **funci√≥n de activaci√≥n**.

### **Perceptr√≥n**

El **perceptr√≥n**, desarrollado por **Frank Rosenblatt** en 1958, es el modelo m√°s simple de una red neuronal. Se trata de un clasificador binario, es decir, un modelo que clasifica entradas en dos clases. El perceptr√≥n consiste en una neurona cuya salida depende de la suma ponderada de las entradas y un **sesgo** (bias). 

### **Funciones de Activaci√≥n**

Las **funciones de activaci√≥n** son esenciales para introducir no linealidades en el modelo, permitiendo que las redes neuronales resuelvan problemas complejos. En el caso del perceptr√≥n, se utiliza una **funci√≥n umbral** que asigna una salida de **1** o **0** dependiendo de si la suma ponderada de las entradas supera un cierto umbral.

### **Interpretaci√≥n Geom√©trica**

Desde una perspectiva geom√©trica, el perceptr√≥n puede visualizarse como un **separador lineal**. La combinaci√≥n de entradas \( x \) y pesos \( w \) define un **hiperplano** en el espacio de entrada, y el perceptr√≥n es capaz de separar las clases mediante este hiperplano. Sin embargo, este enfoque solo es efectivo cuando el problema es **linealmente separable**.

### **Limitaciones del Perceptr√≥n**

A pesar de su simplicidad, el perceptr√≥n tiene limitaciones. **Minsky y Papert** (1968) demostraron que el perceptr√≥n no puede resolver problemas que no sean linealmente separables, como el cl√°sico problema **XOR**. Esto se debe a que no existe un √∫nico hiperplano que pueda dividir correctamente los puntos de clase 0 y clase 1 en el espacio de entrada para problemas no lineales.

### **Redes Neuronales Multicapa (MLP)**

Para superar esta limitaci√≥n, se introducen las **redes neuronales multicapa** (**MLP** - Multi-Layer Perceptron), que consisten en varias capas de neuronas. Estas redes permiten la construcci√≥n de fronteras de decisi√≥n **no lineales**, lo que las hace capaces de resolver problemas complejos como **XOR**. En un **MLP**, los datos se procesan a trav√©s de m√∫ltiples capas: **entrada**, **capas ocultas** y **salida**. Cada capa oculta introduce m√°s no linealidad al sistema, permitiendo a la red aprender representaciones m√°s complejas.

### **Proceso de Entrenamiento del Perceptr√≥n**

El **aprendizaje del perceptr√≥n** se realiza mediante un proceso iterativo en el que el modelo ajusta sus pesos para minimizar el error de predicci√≥n. El proceso incluye los siguientes pasos:
1. **Datos**: Se presentan ejemplos con entradas \( X \) y salidas \( Y \).
2. **Modelo**: Se utiliza un modelo con pesos inicializados aleatoriamente.
3. **Predicci√≥n**: El modelo realiza una predicci√≥n calculando los valores con los pesos actuales.
4. **Error**: El modelo compara la predicci√≥n con la salida real.
5. **Ajuste de Pesos**: Los pesos se ajustan seg√∫n el error, utilizando un algoritmo de optimizaci√≥n (como el **descenso de gradiente**).
6. **Repetir**: El proceso se repite hasta que el modelo minimice el error.

### **Descenso de Gradiente**

El **descenso de gradiente** es el algoritmo de optimizaci√≥n m√°s com√∫nmente utilizado en el entrenamiento de redes neuronales. El objetivo es encontrar los valores de los pesos que minimicen el error del modelo. Esto se logra ajustando los pesos en la direcci√≥n opuesta al gradiente de la funci√≥n de p√©rdida, utilizando el c√°lculo de derivadas parciales.

---

## Actividades

| Actividad                                             | Resultado esperado                                                                                                 |
| ----------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------ |
| **1. Explorando el Perceptr√≥n**                       | Configuraci√≥n y visualizaci√≥n de un perceptr√≥n b√°sico aplicado a la l√≥gica booleana.                               |
| **2. Resolver AND**                                   | El perceptr√≥n clasifica correctamente la tabla de verdad de la operaci√≥n AND.                                      |
| **3. Resolver OR**                                    | El perceptr√≥n clasifica correctamente la tabla de verdad de la operaci√≥n OR.                                       |
| **4. Resolver NOT**                                   | El perceptr√≥n invierte correctamente la entrada seg√∫n la operaci√≥n NOT.                                            |
| **5. Resolver XOR: el l√≠mite del perceptr√≥n**         | El perceptr√≥n no logra clasificar correctamente la tabla de verdad de la operaci√≥n XOR.                            |
| **6. Resolver XOR con una red neuronal multicapa**    | Implementaci√≥n de un MLP que clasifica correctamente los patrones de XOR con precisi√≥n del 100%.                   |
| **7. Visualizaci√≥n de la Arquitectura de la Red MLP** | Gr√°fico de la arquitectura del MLP que muestra la capa de entrada, capa oculta y salida.                           |
| **8. Visualizaci√≥n de la Superficie de Decisi√≥n**     | Comparaci√≥n visual de la frontera de decisi√≥n generada por un perceptr√≥n simple y un MLP.                          |
| **9. Dataset Real con MLP**                           | Aplicaci√≥n del MLP a un conjunto de datos realista, mostrando una precisi√≥n del 90%.                               |
| **10. Red Neuronal con TensorFlow**                   | Implementaci√≥n de un modelo en TensorFlow y evaluaci√≥n del rendimiento en un conjunto de datos real.               |
| **11. Visualizar Entrenamiento**                      | Visualizaci√≥n de las curvas de aprendizaje para analizar la convergencia y posibles problemas de overfitting.      |
| **12. PyTorch Lightning (Bonus)**                     | Implementaci√≥n del modelo usando PyTorch Lightning, mejorando la modularidad y eficiencia del entrenamiento.       |
| **13. Entrenar PyTorch Lightning**                    | Evaluaci√≥n final de un modelo entrenado con PyTorch Lightning, mostrando una precisi√≥n similar a otros frameworks. |
| **14. Visualizaci√≥n de Matriz de Confusi√≥n**          | Comparaci√≥n de matrices de confusi√≥n para los tres modelos: Scikit-learn, TensorFlow y PyTorch Lightning.          |
| **15. Preguntas de Reflexi√≥n**                        | Reflexi√≥n sobre los resultados obtenidos y la aplicabilidad de cada enfoque para diferentes problemas.             |
| **16: EXTRA: Dataset de C√≠rculos Conc√©ntricos**       | El perceptr√≥n b√°sico no logra resolver correctamente el problema de los c√≠rculos conc√©ntricos.                     |

---

### üß† 1. Explorando el Perceptr√≥n

En este primer paso se configura un **perceptr√≥n b√°sico** para aprender y visualizar c√≥mo funciona este algoritmo en el contexto de la l√≥gica booleana. El perceptr√≥n es el modelo m√°s simple de red neuronal, utilizado para clasificaci√≥n binaria. En este caso, se aplica a la tabla de verdad de una puerta l√≥gica.

### üéØ 2. Resolver AND

En este paso resolvemos la l√≥gica booleana para la operaci√≥n **AND** usando un **perceptr√≥n b√°sico**. El objetivo es entrenar el perceptr√≥n para que clasifique correctamente las salidas de una operaci√≥n AND en funci√≥n de dos entradas (`x1`, `x2`).

#### üîë Decisiones tomadas

Se aplicaron las siguientes decisiones para resolver el problema de la puerta l√≥gica **AND**:

**Pesos y Bias**:

   - Se asignaron pesos de **0.5** para ambas entradas (`x1` y `x2`) y un **bias** de **-0.7**.
   - Este bias se eligi√≥ para garantizar que la salida del perceptr√≥n sea **1** solo cuando ambas entradas sean **1**, lo que corresponde a la operaci√≥n AND.

#### üìä Resultado obtenido

Al ejecutar el c√≥digo, obtuvimos el siguiente resultado en la consola:

1Ô∏è‚É£ PROBLEMA AND: Solo verdadero cuando AMBAS entradas son 1

x1| x2| AND esperado

0 | 0 | 0

0 | 1 | 0

1 | 0 | 0

1 | 1 | 1

Probando AND con pesos: w1=0.5, w2=0.5, bias=-0.7

0,0 ‚Üí 0 (esperado 0) ‚úÖ

0,1 ‚Üí 0 (esperado 0) ‚úÖ

1,0 ‚Üí 0 (esperado 0) ‚úÖ

1,1 ‚Üí 1 (esperado 1) ‚úÖ

Se gener√≥ un gr√°fico que se encuentra en evidencias como gr√°fico 1.

La visualizaci√≥n generada mostr√≥ los siguientes puntos y la l√≠nea de separaci√≥n:

- **Puntos rojos (‚óã)**: Representan la clase 0 (salida falsa).
- **Puntos azules (‚ñ†)**: Representan la clase 1 (salida verdadera).
- **L√≠nea verde**: Muestra la frontera de decisi√≥n generada por el perceptr√≥n. La l√≠nea se encuentra correctamente separando las dos clases.

#### üìà An√°lisis

- **Predicciones**: El perceptr√≥n logra clasificar correctamente todos los casos de la tabla de verdad para **AND**, tal como se esperaba.
- **Visualizaci√≥n**: La l√≠nea verde generada por el perceptr√≥n muestra claramente la separaci√≥n entre las dos clases. Dado que este es un problema linealmente separable, el perceptr√≥n funciona correctamente y traza una l√≠nea que divide de manera efectiva las entradas de clase 0 (rojos) y clase 1 (azules).
  
  Este comportamiento confirma que el perceptr√≥n es capaz de resolver problemas l√≥gicos simples como AND, ya que solo necesita ajustar los pesos y el bias para encontrar la l√≠nea de decisi√≥n correcta.

Este paso sirvi√≥ para ilustrar c√≥mo un **perceptr√≥n** b√°sico puede resolver problemas de clasificaci√≥n binaria simples, como la operaci√≥n AND. A trav√©s de este ejemplo, se entiende la capacidad del perceptr√≥n para aprender una **frontera de decisi√≥n lineal** que separa las dos clases en problemas sencillos.

La visualizaci√≥n tambi√©n ayuda a comprender c√≥mo los puntos de datos y la l√≠nea de separaci√≥n interact√∫an, lo que es fundamental para entender el funcionamiento de redes neuronales m√°s complejas en el futuro.

### üéØ 3. Resolver OR

En este paso, resolvemos el problema de la l√≥gica booleana **OR** usando el **perceptr√≥n**. El objetivo es entrenar un perceptr√≥n para que clasifique correctamente los valores de la operaci√≥n OR en funci√≥n de dos entradas (`x1`, `x2`).

#### üîë Decisiones tomadas

Se aplicaron las siguientes decisiones para resolver el problema de la puerta l√≥gica **OR**:

 **Pesos y Bias**:

   - Se asignaron pesos de **0.5** para ambas entradas (`x1` y `x2`) y un **bias** de **-0.2**.
   - Este bias se eligi√≥ para permitir que una de las entradas sea suficiente para activar el perceptr√≥n. Es m√°s permisivo que el caso anterior, ya que la operaci√≥n OR debe devolver **1** cuando al menos una entrada es **1**.

 **Visualizaci√≥n**:

   - Se grafic√≥ el perceptr√≥n con sus pesos y la l√≠nea de separaci√≥n generada por el perceptr√≥n para ver c√≥mo divide las dos clases (0 y 1) en el espacio bidimensional. Esto se encuentra en evidencias como gr√°fica 2.

#### üìä Resultado obtenido

Al ejecutar el c√≥digo, obtuvimos el siguiente resultado en la consola:

2Ô∏è‚É£ PROBLEMA OR: Verdadero cuando AL MENOS UNA entrada es 1
x1| x2| OR esperado
0 | 0 | 0
0 | 1 | 1
1 | 0 | 1
1 | 1 | 1

Probando OR con pesos: w1=0.5, w2=0.5, bias=-0.2

0,0 ‚Üí 0 (esperado 0) ‚úÖ

0,1 ‚Üí 1 (esperado 1) ‚úÖ

1,0 ‚Üí 1 (esperado 1) ‚úÖ

1,1 ‚Üí 1 (esperado 1) ‚úÖ

La visualizaci√≥n generada mostr√≥ los siguientes puntos y la l√≠nea de separaci√≥n:

- **Puntos rojos (‚óã)**: Representan la clase 0 (salida falsa).
- **Puntos azules (‚ñ†)**: Representan la clase 1 (salida verdadera).
- **L√≠nea verde**: Muestra la frontera de decisi√≥n generada por el perceptr√≥n. La l√≠nea se encuentra correctamente separando las dos clases.

#### üìà An√°lisis

- **Predicciones**: El perceptr√≥n logra clasificar correctamente todos los casos de la tabla de verdad para **OR**, tal como se esperaba.
- **Visualizaci√≥n**: La l√≠nea verde generada por el perceptr√≥n muestra claramente la separaci√≥n entre las dos clases. Al igual que en el caso de **AND**, este problema tambi√©n es linealmente separable, por lo que el perceptr√≥n genera una l√≠nea que divide eficazmente las dos clases.

  Este comportamiento confirma que el perceptr√≥n es capaz de resolver problemas l√≥gicos simples como OR, ya que solo necesita ajustar los pesos y el bias para encontrar la l√≠nea de decisi√≥n correcta.

### üéØ 4. Resolver NOT

En este paso, se resuelve el problema de la l√≥gica booleana **NOT**, utilizando un perceptr√≥n simple para invertir una √∫nica entrada. El perceptr√≥n debe generar una salida **1** cuando la entrada es **0** y una salida **0** cuando la entrada es **1**.

#### üîë Decisiones tomadas

 **Pesos y Bias**:

   - Se asignaron un **peso negativo (-1)** para la entrada y un **bias positivo (0.5)**.
   - El peso negativo asegura que cuando la entrada es **0**, la salida sea **1**, y el bias positivo permite que la activaci√≥n ocurra antes de que la entrada alcance **1**.

**Visualizaci√≥n**:

   - Se grafic√≥ el comportamiento del perceptr√≥n en un gr√°fico de 1D, mostrando c√≥mo la entrada se divide en dos clases: **0** (rojo) y **1** (azul). 
   - La l√≠nea verde indica el umbral de activaci√≥n del perceptr√≥n, donde ocurre la separaci√≥n entre las clases.

#### üìä Resultado obtenido

Al ejecutar el c√≥digo, se obtuvo el siguiente resultado en la consola:
3Ô∏è‚É£ PROBLEMA NOT: Inversor simple
x | NOT esperado
0 | 1
1 | 0

Probando NOT con peso: w1=-1, bias=0.5

0 ‚Üí 1 (esperado 1) ‚úÖ

1 ‚Üí 0 (esperado 0) ‚úÖ

La visualizaci√≥n generada mostr√≥ los siguientes puntos y la l√≠nea de separaci√≥n(gr√°fica 3):

- **Puntos azules (‚óè)**: Representan la clase **1** (NOT = 1).
- **Puntos rojos (‚óè)**: Representan la clase **0** (NOT = 0).
- **L√≠nea verde**: Muestra el umbral de decisi√≥n generado por el perceptr√≥n. La l√≠nea divide claramente las dos clases.

#### üìà An√°lisis

- **Predicciones**: El perceptr√≥n logra clasificar correctamente los dos casos de la tabla de verdad para **NOT**.
- **Visualizaci√≥n**: La l√≠nea verde indica el umbral en **x = 0.5**, donde el perceptr√≥n cambia su salida de **1** a **0**. Esto demuestra c√≥mo el perceptr√≥n es capaz de "invertir" el valor de la entrada.

  El perceptr√≥n genera una clara separaci√≥n entre las dos clases, con un solo punto de activaci√≥n en el umbral.

### üß© 5. Resolver XOR: el l√≠mite del perceptr√≥n simple

En este paso se aborda el cl√°sico **problema XOR (Exclusive OR)**, utilizado hist√≥ricamente para demostrar las **limitaciones del perceptr√≥n simple**.

El objetivo es comprobar si un perceptr√≥n con una sola capa y frontera de decisi√≥n lineal puede clasificar correctamente los datos del operador l√≥gico XOR.

La operaci√≥n XOR devuelve **1 solo cuando las dos entradas son diferentes**, es decir:

| x1 | x2 | XOR esperado |
| -- | -- | ------------ |
| 0  | 0  | 0            |
| 0  | 1  | 1            |
| 1  | 0  | 1            |
| 1  | 1  | 0            |

A diferencia de **AND** y **OR**, esta operaci√≥n **no es linealmente separable**, lo que significa que no existe una l√≠nea recta capaz de dividir correctamente las clases (0 y 1) en el plano.

#### üìä Resultados obtenidos

El experimento arroj√≥ los siguientes resultados:

| Intento | Descripci√≥n      | Aciertos | Porcentaje |
| ------- | ---------------- | -------- | ---------- |
| 1       | Similar a AND    | 3/4      | 75%        |
| 2       | AND estricto     | 1/4      | 25%        |
| 3       | Similar a OR     | 3/4      | 75%        |
| 4       | Pesos diferentes | 1/4      | 25%        |

üí• **Resultado final:**
Ninguna configuraci√≥n logr√≥ clasificar correctamente los cuatro casos.

El mejor resultado fue **3 aciertos de 4 (75%)**, lo que confirma que **un perceptr√≥n simple no puede resolver XOR**.

* En los intentos 1 y 3, el perceptr√≥n logra clasificar correctamente tres de los cuatro casos, pero siempre falla en el punto (1,1) o (0,0).
* En los intentos 2 y 4, la elecci√≥n de pesos y bias m√°s extremos genera l√≠neas que no separan adecuadamente las clases, reduciendo la precisi√≥n a solo un acierto.
* Visualmente, los puntos **azules (‚ñ†)** representan la clase 1 y los **rojos (‚óã)** la clase 0.
  La l√≠nea verde corresponde a la frontera de decisi√≥n del perceptr√≥n. En todos los casos, se observa que **no existe una √∫nica l√≠nea que divida perfectamente ambas clases**.

### üíª 6. Resolver XOR con una red neuronal multicapa (MLP)

En este paso se busca superar la limitaci√≥n demostrada anteriormente: el **perceptr√≥n simple no puede resolver el problema XOR**.

Para ello, se implementa una **red neuronal multicapa (MLP, Multi-Layer Perceptron)**, que incorpora una **capa oculta** y una **funci√≥n de activaci√≥n no lineal**, permitiendo construir fronteras de decisi√≥n m√°s complejas.

El problema XOR (Exclusive OR) presenta un desaf√≠o cl√°sico en el aprendizaje autom√°tico: **no es linealmente separable**.

El perceptr√≥n simple solo puede trazar una l√≠nea recta en el espacio de entrada, mientras que el MLP puede combinar m√∫ltiples l√≠neas y curvas mediante **neuronas ocultas** y **activaciones no lineales**.

As√≠, el MLP puede **aprender relaciones no lineales** entre las variables de entrada `x1` y `x2`, logrando clasificar correctamente los cuatro patrones de XOR.

#### üîë Decisiones tomadas

* **Cantidad de neuronas ocultas:** se utiliz√≥ una capa oculta con 4 neuronas (`hidden_layer_sizes=(4,)`), suficiente para representar la no linealidad del problema XOR.
* **Funci√≥n de activaci√≥n:** se seleccion√≥ **tanh**, que introduce no linealidad al permitir valores en el rango (-1, 1).

#### üìä Resultados obtenidos

| x1 | x2 | Esperado | Predicci√≥n | ‚úì |
| -- | -- | -------- | ---------- | - |
| 0  | 0  | 0        | 0          | ‚úì |
| 0  | 1  | 1        | 1          | ‚úì |
| 1  | 0  | 1        | 1          | ‚úì |
| 1  | 1  | 0        | 0          | ‚úì |

üéØ **Accuracy: 100.0%**

El modelo MLP logr√≥ **clasificar correctamente los cuatro patrones de XOR**, demostrando su capacidad para capturar **relaciones no lineales** entre las entradas.

A diferencia del perceptr√≥n simple:

* Cada **neurona de la capa oculta** genera una frontera de decisi√≥n parcial.
* La **combinaci√≥n de activaciones** permite construir regiones en el plano que separan correctamente las clases 0 y 1.
* El uso de **tanh** facilita la convergencia al modelar relaciones tanto positivas como negativas.

Se observ√≥ una **advertencia de convergencia** (`ConvergenceWarning`), lo que indica que el optimizador alcanz√≥ el l√≠mite de iteraciones sin finalizar completamente el ajuste. Sin embargo, esto **no afect√≥ el rendimiento final**, ya que el modelo logr√≥ una precisi√≥n perfecta.

La implementaci√≥n del **MLPClassifier** permiti√≥ superar la limitaci√≥n del perceptr√≥n simple.
üëâ Gracias a su **capa oculta** y **activaci√≥n no lineal**, el MLP aprendi√≥ correctamente el patr√≥n XOR, alcanzando un **100% de acierto**.

Este resultado valida la importancia de las **redes neuronales multicapa** como base del aprendizaje profundo actual, y marca el paso desde los modelos lineales hacia arquitecturas m√°s flexibles y potentes.

### üé® 7. Visualizaci√≥n de la Arquitectura de la Red MLP

En este paso se representa gr√°ficamente la arquitectura del **MLP (Multi-Layer Perceptron)** entrenado para resolver el problema **XOR**, mostrando c√≥mo las neuronas y sus conexiones permiten modelar relaciones no lineales entre las entradas.


El MLP implementado tiene la siguiente estructura:
**2 neuronas de entrada ‚Üí 4 neuronas ocultas ‚Üí 1 neurona de salida**

Este dise√±o, conocido como **2 ‚Üí 4 ‚Üí 1**, es suficiente para capturar la no linealidad del problema XOR, ya que la capa oculta puede generar **fronteras de decisi√≥n combinadas**.

La visualizaci√≥n generada muestra tres capas (gr√°fica 5):

* **Entrada:** dos neuronas (`x1`, `x2`)
* **Capa oculta:** cuatro neuronas con activaci√≥n no lineal (`tanh`)
* **Salida:** una neurona (`XOR`)

Cada conexi√≥n entre capas representa un **peso entrenable**, ajustado durante el proceso de backpropagation.


#### üìä Resultado visual

#### üîç Par√°metros del modelo

| Capa                 | Neuronas (entrada ‚Üí salida) | Par√°metros        |
| -------------------- | --------------------------- | ----------------- |
| 1 (Entrada ‚Üí Oculta) | 2 ‚Üí 4                       | 12                |
| 2 (Oculta ‚Üí Salida)  | 4 ‚Üí 1                       | 5                 |
| **Total**            | ‚Äî                           | **17 par√°metros** |


La representaci√≥n gr√°fica permite comprender visualmente **c√≥mo el MLP procesa el problema XOR**:

* Cada neurona de la capa oculta genera una combinaci√≥n no lineal de las entradas.
* La neurona de salida integra esas combinaciones para producir la salida XOR correcta.
* Las **conexiones ajustables** y la **activaci√≥n tanh** otorgan flexibilidad para separar regiones no lineales.

El modelo **2 ‚Üí 4 ‚Üí 1** demuestra que incluso una red peque√±a puede resolver problemas imposibles para un perceptr√≥n simple, ilustrando el poder de la **profundidad y no linealidad** en las redes neuronales.

### üåà 8. Visualizaci√≥n de la Superficie de Decisi√≥n

En este paso se compara visualmente c√≥mo **un perceptr√≥n simple** y un **MLP (Multi-Layer Perceptron)** separan los datos del problema XOR.

Esta comparaci√≥n permite observar las diferencias fundamentales entre un modelo **lineal** y uno **no lineal**.

El **perceptr√≥n simple** solo puede separar datos mediante una **l√≠nea recta**, lo cual es insuficiente para el problema XOR, que requiere una frontera de decisi√≥n **curva**.

Por otro lado, el **MLP** con una capa oculta puede **modelar superficies de decisi√≥n complejas**, permitiendo separar correctamente los puntos de XOR.

#### üìä Resultado obtenido:

**Interpretaci√≥n del gr√°fico:**

| Modelo         | Tipo de frontera | Resultado               |
| -------------- | ---------------- | ----------------------- |
| **Perceptr√≥n** | L√≠nea recta      | ‚ùå No puede separar XOR |
| **MLP**        | Superficie curva | ‚úÖ ¬°Puede separar XOR!  |

En la figura:

* üî¥ **Zonas rojas** ‚Üí predicci√≥n de clase 0
* üîµ **Zonas azules** ‚Üí predicci√≥n de clase 1
* ‚ö´ **Puntos** ‚Üí datos reales del conjunto XOR

1. **Perceptr√≥n:**

   * Genera una **√∫nica frontera lineal**.
   * No logra separar los puntos `(0,0)` y `(1,1)` del resto.
   * Falla al capturar la estructura no lineal del XOR.

2. **MLP:**

   * Construye **una superficie de decisi√≥n curva**.
   * Combina varias activaciones no lineales de las neuronas ocultas.
   * Separa correctamente las clases incluso cuando no son linealmente separables.


El an√°lisis visual confirma que el **MLP logra resolver XOR** gracias a su capacidad de **aprender representaciones no lineales**.

Mientras el perceptr√≥n simple s√≥lo traza una recta, el MLP **deforma el espacio de entrada** para crear **regiones curvas de decisi√≥n** que distinguen ambas clases.

> El MLP no solo aprende pesos, sino tambi√©n una nueva forma de representar los datos ‚Äîla clave del aprendizaje profundo moderno.


### üß† 9. Dataset Real con MLP

En esta etapa se aplica el **MLP (Multi-Layer Perceptron)** a un conjunto de datos **realista** generado artificialmente con m√∫ltiples caracter√≠sticas, simulando un problema de clasificaci√≥n binaria complejo.

#### üß© Decisiones tomadas

1. **`train_test_split`**
   

   * Se utiliz√≥ para dividir el dataset en entrenamiento (70%) y prueba (30%), siguiendo una pr√°ctica est√°ndar para validar el desempe√±o del modelo en datos no vistos.

2. **`hidden_layer_sizes=(64, 32)`**
   

   * Se opt√≥ por dos capas ocultas con 64 y 32 neuronas respectivamente.

   * Esta configuraci√≥n permite que la primera capa capture relaciones complejas entre las 20 variables.
   * La segunda capa refina la representaci√≥n antes de la salida.
   * Es un equilibrio entre **capacidad de aprendizaje** y **evitar sobreajuste**.

3. **`activation='relu'`**
   

   * Se eligi√≥ la funci√≥n de activaci√≥n **ReLU (Rectified Linear Unit)**, recomendada por su rendimiento en redes profundas y su capacidad para evitar el problema del gradiente desapareciente.

4. **`mlp_real.fit()`**
   

   * Es el m√©todo est√°ndar de entrenamiento. Ajusta los pesos mediante **backpropagation** y el optimizador **Adam**, que combina eficiencia y estabilidad.


#### üìä Resultados obtenidos

```
üìä Resultados MLP en dataset real:
  Training Accuracy: 100.0%
  Test Accuracy: 90.3%
  Arquitectura: 20 ‚Üí (64, 32) ‚Üí 2
```

* El **100% de acierto en entrenamiento** muestra que el modelo logra aprender perfectamente los patrones del conjunto de entrenamiento.
* El **90.3% en prueba** confirma que el MLP **generaliza bien**, aunque existe una ligera diferencia que sugiere **posible sobreajuste leve**.
* La arquitectura seleccionada demuestra ser **adecuada para datasets tabulares medianos**, sin necesidad de regularizaci√≥n adicional.

Este experimento demuestra c√≥mo un **MLP puede resolver problemas reales de clasificaci√≥n** con datos de alta dimensionalidad.

Su capacidad de **aprender representaciones jer√°rquicas** le permite superar ampliamente a modelos lineales simples, ofreciendo una frontera de decisi√≥n **compleja y flexible**.

> El MLP no solo resuelve XOR, sino que tambi√©n escala eficazmente a datasets reales, mostrando su potencia como modelo de clasificaci√≥n universal.

### üíª 10. Red Neuronal con TensorFlow

En esta secci√≥n se implementa una **red neuronal profesional** utilizando la librer√≠a **TensorFlow (Keras)**, con el objetivo de comparar su rendimiento frente al MLP de *scikit-learn* sobre el mismo dataset.

#### üß© Decisiones t√©cnicas

1. **Arquitectura:**


   * Dos capas ocultas (`64` y `32` neuronas) con activaci√≥n `ReLU`.
   * Capa de salida con `sigmoid` para clasificaci√≥n binaria.
   * Arquitectura: `20 ‚Üí 64 ‚Üí 32 ‚Üí 1`.

2. **Funci√≥n de p√©rdida y optimizador:**


   * `binary_crossentropy` como funci√≥n de p√©rdida, ideal para tareas binarias.
   * `adam` como optimizador por su eficiencia y r√°pida convergencia.

3. **Hiperpar√°metros:**


   * **√âpocas:** 30, lo que permiti√≥ una curva de aprendizaje estable.
   * **Batch size:** 32, un valor est√°ndar que balancea estabilidad y velocidad.

#### üìä Resultados obtenidos


Dataset: 700 samples, 20 features

üéØ Resultados TensorFlow:
  
  Training Accuracy: 100.0%
  
  Test Accuracy: 93.7%
  
  Par√°metros totales: 3,457

* El **100% de acierto en entrenamiento** muestra que la red logr√≥ aprender perfectamente el patr√≥n subyacente del dataset.
* El **93.7% en test** indica un **ligero sobreajuste**, pero con una **excelente generalizaci√≥n**.
* TensorFlow demostr√≥ **mayor eficiencia y control** sobre el entrenamiento comparado con la implementaci√≥n previa en *scikit-learn*.

El uso de **TensorFlow** permiti√≥ un entrenamiento m√°s r√°pido, una arquitectura personalizable y una mejora del rendimiento global.

El modelo final muestra que una **red neuronal bien configurada** puede superar los resultados obtenidos con modelos tradicionales de MLP.


### üíª 11. Visualizar Entrenamiento

En este paso se genera una **visualizaci√≥n de las curvas de aprendizaje** del modelo entrenado en TensorFlow, con el fin de analizar su comportamiento durante las distintas √©pocas de entrenamiento y detectar posibles signos de **overfitting** o problemas de **convergencia**.

#### üîß Decisiones tomadas

Para graficar las m√©tricas se utiliz√≥ la biblioteca **`matplotlib.pyplot`**, una de las herramientas m√°s comunes en Python para visualizaci√≥n de datos.  
El espacio en blanco del c√≥digo:

se complet√≥ con:

import matplotlib.pyplot as plt

Esta decisi√≥n se tom√≥ porque matplotlib.pyplot permite crear f√°cilmente gr√°ficos de l√≠neas, ajustar etiquetas, t√≠tulos y subplots, lo cual es ideal para visualizar m√©tricas de entrenamiento como loss (p√©rdida) y accuracy (precisi√≥n).

#### üìä Resultado obtenido

El resultado se muestra en la gr√°fica 6 en evidencias:

El gr√°fico de la izquierda representa la p√©rdida (loss) y el de la derecha la precisi√≥n (accuracy):

En la p√©rdida, se observa una disminuci√≥n constante tanto en entrenamiento como en validaci√≥n, lo que indica que el modelo est√° aprendiendo de manera estable.

En la precisi√≥n, la curva de entrenamiento alcanza valores cercanos a 1.0, mientras que la de validaci√≥n se estabiliza alrededor de 0.93‚Äì0.94.

* Convergencia:
El modelo converge correctamente. Las curvas de p√©rdida y precisi√≥n muestran una tendencia clara hacia la estabilizaci√≥n despu√©s de unas pocas √©pocas.

* Overfitting:
Aunque la precisi√≥n de entrenamiento alcanza el 100% y la de validaci√≥n es ligeramente inferior (‚âà93%), la diferencia es moderada. Esto sugiere un leve sobreajuste, pero dentro de un rango aceptable.

La red generaliza bien a datos no vistos.

El an√°lisis visual confirma que el entrenamiento fue exitoso.

El modelo aprendi√≥ los patrones del dataset sin sobreajustarse significativamente, logrando una convergencia estable y precisa.

Las curvas tambi√©n evidencian un proceso de entrenamiento bien configurado en t√©rminos de n√∫mero de √©pocas, tasa de aprendizaje y arquitectura.

### üíª 12. PyTorch Lightning (Bonus)

En este paso se implementa una versi√≥n alternativa del modelo utilizando **PyTorch Lightning**, un framework que simplifica y estructura el entrenamiento de redes neuronales en **PyTorch**.  
Este enfoque busca **modularizar el c√≥digo**, mejorar la **legibilidad** y facilitar la **reutilizaci√≥n** del modelo.

#### üîß Decisiones tomadas

Para este paso se completaron los espacios en blanco del c√≥digo. Estas decisiones se tomaron por los siguientes motivos:

* nn.ReLU(True) se utiliza como funci√≥n de activaci√≥n no lineal, introduciendo la capacidad del modelo de aprender relaciones complejas entre las variables de entrada.

El par√°metro inplace=True permite optimizar el uso de memoria.

* La segunda capa oculta de 32 neuronas se defini√≥ como un compromiso entre capacidad de aprendizaje y eficiencia.

* El optimizador Adam es una opci√≥n robusta y ampliamente usada, que combina las ventajas de AdaGrad y RMSProp, ajustando autom√°ticamente la tasa de aprendizaje.

#### üìä Resultado obtenido

Al ejecutar el c√≥digo, se obtiene la siguiente salida:

üéØ PyTorch Lightning model created!
Input features: 20
Parameters: 3,490


Esto indica que el modelo fue creado correctamente, detectando **20 variables de entrada** y un total de **3.490 par√°metros entrenables**.

**Estructura del modelo:**  
El uso de `nn.Sequential` permite definir la arquitectura de manera clara y compacta.  
Se emplean dos capas ocultas con activaciones **ReLU**, seguidas de una capa de salida con **dos neuronas** para clasificaci√≥n binaria.

**Ventajas de PyTorch Lightning:**  
Este framework separa la l√≥gica del modelo (`forward`) de la del entrenamiento (`training_step`) y del optimizador (`configure_optimizers`), lo que mejora la **organizaci√≥n del c√≥digo**.  
Adem√°s, facilita el **registro de m√©tricas** y el **manejo de GPU** sin necesidad de modificar la l√≥gica base del modelo.

### üèãÔ∏è 13. Entrenar PyTorch Lightning

En este paso se realiza el **entrenamiento y evaluaci√≥n del modelo implementado con PyTorch Lightning**.  
El objetivo es comprobar el desempe√±o del modelo y observar las m√©tricas finales de p√©rdida (**loss**) y precisi√≥n (**accuracy**) sobre el conjunto de prueba.

#### üîß Decisiones tomadas

Los espacios en blanco del c√≥digo se completaron. Las razones de estas decisiones fueron:

* batch_size=32: valor com√∫n que equilibra velocidad y estabilidad del entrenamiento.

* max_epochs=30: cantidad suficiente para permitir la convergencia del modelo sin sobreentrenar.

* logger=False: se desactiva el registro en archivo para simplificar la ejecuci√≥n en entorno de notebook.

* trainer.fit() y trainer.test(): m√©todos nativos de PyTorch Lightning para entrenar y evaluar el modelo, respectivamente.

#### üìä Resultado obtenido

Durante la ejecuci√≥n se muestran mensajes informativos de **PyTorch Lightning** sobre el entorno de hardware, la estructura del modelo y el progreso de las √©pocas.  

El resumen de resultados finales fue el siguiente:

üéØ PyTorch Lightning model created!

Input features: 20

Parameters: 3,490

üöÄ Entrenando con PyTorch Lightning...

üìä Evaluando modelo...

üéØ Resultados: [{'test_loss': 0.1799493432044983, 'test_acc': 0.9333333373069763}]


Esto indica que el modelo alcanz√≥ una **p√©rdida de 0.18** y una **precisi√≥n del 93.3%** sobre los datos de prueba, resultados muy similares a los obtenidos previamente con **TensorFlow**.


**Entrenamiento:**  
El modelo se entren√≥ correctamente durante **30 √©pocas**, mostrando una **convergencia estable**.  
El progreso fue mostrado con una barra din√°mica gracias al par√°metro `enable_progress_bar=True`.

**Evaluaci√≥n:**  
Las m√©tricas finales reflejan un **buen desempe√±o y generalizaci√≥n**, confirmando que el modelo entrenado en **PyTorch Lightning** reproduce el rendimiento del modelo original.

**Ventajas observadas:**  

- C√≥digo m√°s limpio y estructurado.  
- Menor cantidad de c√≥digo repetitivo (por ejemplo, pasos de entrenamiento y validaci√≥n).  
- Integraci√≥n autom√°tica de m√©tricas y control de progreso.  
- Mayor reproducibilidad gracias al modo determinista.

El uso de **PyTorch Lightning** permite entrenar y evaluar modelos de forma **m√°s ordenada, eficiente y profesional**, manteniendo el mismo nivel de rendimiento que las implementaciones tradicionales.

### üé® 14. Visualizaci√≥n de Matriz de Confusi√≥n

Durante este paso se generaron las **matrices de confusi√≥n comparativas** para los tres frameworks utilizados:  
**Scikit-learn**, **TensorFlow** y **PyTorch Lightning**.


#### üìà An√°lisis de las Matrices de Confusi√≥n

La gr√°fica se encuentra en evidencias como gr√°fica 8.

- La **diagonal principal (TN + TP)** representa las **predicciones correctas**, es decir, los casos en que el modelo clasific√≥ correctamente ambas clases.  
- La **diagonal secundaria (FP + FN)** indica los **errores de clasificaci√≥n**.

**Observaciones:**

- En los tres modelos se observa un **rendimiento muy similar**, con ligeras variaciones en los falsos positivos y falsos negativos.  
- **Scikit-learn MLP** presenta 85 verdaderos negativos y 52 verdaderos positivos, logrando un buen equilibrio.  
- **TensorFlow** tiene un leve aumento en falsos positivos (11) y falsos negativos (7), manteniendo a√∫n un alto nivel de acierto.  
- **PyTorch Lightning** muestra resultados pr√°cticamente equivalentes, con 84 verdaderos negativos y 51 verdaderos positivos.

Las tres implementaciones logran un **rendimiento comparable**, evidenciando la consistencia del modelo m√°s all√° del framework utilizado.  

El an√°lisis confirma que la arquitectura general y los datos tienen un mayor impacto en el desempe√±o que la librer√≠a empleada para el entrenamiento.

### üí≠ 15. Preguntas de Reflexi√≥n

#### üîπ ¬øPor qu√© AND, OR y NOT funcionaron pero XOR no?

El perceptr√≥n simple puede resolver √∫nicamente **problemas linealmente separables**, es decir, aquellos que pueden dividirse con una l√≠nea recta en el plano de entrada.  

En el caso de **XOR**, los puntos positivos y negativos est√°n dispuestos de forma que **no existe una frontera lineal** que los separe correctamente.  

Por ello, mientras que **AND, OR y NOT** pueden resolverse con un √∫nico plano de decisi√≥n, **XOR requiere al menos una capa oculta adicional** para combinar m√∫ltiples l√≠neas de decisi√≥n.

#### üîπ ¬øCu√°l es la diferencia clave entre los pesos de AND vs OR?

La diferencia principal radica en el **umbral de activaci√≥n**. 

- En la funci√≥n **AND**, los pesos deben ser mayores o el umbral m√°s alto, ya que solo se activa si **ambas entradas** son 1.  
- En cambio, en **OR**, basta con que una entrada sea 1, por lo que el **umbral de activaci√≥n es menor** y los pesos son menos restrictivos.

#### üîπ ¬øQu√© otros problemas del mundo real ser√≠an como XOR?

Ejemplos t√≠picos son aquellos en los que **una sola condici√≥n debe cumplirse, pero no ambas a la vez**, como:

- Un sistema de control que activa una alarma **si una puerta o una ventana est√° abierta, pero no las dos**.  
- Decisiones tipo **‚Äúesto o aquello, pero no ambos‚Äù**, como sem√°foros, interruptores o l√≥gicas exclusivas en sistemas de seguridad.

#### üîπ ¬øPor qu√© sklearn MLP puede resolver XOR pero un perceptr√≥n no?

El **MLP (Multilayer Perceptron)** de sklearn incluye **capas ocultas y funciones de activaci√≥n no lineales**, lo que le permite crear **m√∫ltiples l√≠neas de decisi√≥n** y combinar regiones del espacio de entrada.  

El perceptr√≥n simple solo tiene **una frontera lineal**, por lo que no puede representar relaciones no lineales como XOR.

#### üîπ ¬øCu√°l es la principal diferencia entre TensorFlow/Keras y sklearn MLP?

La diferencia fundamental est√° en el **nivel de control**:

- **Scikit-learn MLP** ofrece una interfaz de alto nivel, simple y orientada a resultados r√°pidos.  
- **TensorFlow/Keras** permite **definir y personalizar cada detalle del modelo**, el entrenamiento, las m√©tricas y los callbacks, siendo m√°s flexible pero tambi√©n m√°s complejo.

#### üîπ ¬øPor qu√© TensorFlow usa `epochs` y `batch_size` mientras sklearn MLP no?

En **TensorFlow**, el entrenamiento se realiza **por lotes (batch training)**, lo que permite controlar la frecuencia de actualizaci√≥n de los pesos y mejorar el rendimiento en GPU. 

En **scikit-learn**, el MLP entrena el modelo **procesando todo el conjunto de datos de una vez**, ocultando estos par√°metros al usuario para simplificar el uso.

#### üîπ ¬øCu√°ndo usar√≠as `sigmoid` vs `relu` como funci√≥n de activaci√≥n?

- **Sigmoid** se utiliza t√≠picamente en la **capa de salida** para problemas de **clasificaci√≥n binaria**, ya que transforma el valor en una probabilidad entre 0 y 1.  
- **ReLU** se usa en las **capas ocultas**, porque evita el problema del gradiente desvanecido y acelera la convergencia durante el entrenamiento.

#### üîπ ¬øQu√© ventaja tiene PyTorch Lightning sobre TensorFlow puro?

**PyTorch Lightning** reduce dr√°sticamente el **c√≥digo repetitivo (boilerplate)** al automatizar el manejo del ciclo de entrenamiento, validaci√≥n y testeo.  

Permite mantener el enfoque en la **l√≥gica del modelo** y no en la infraestructura del entrenamiento, facilitando la experimentaci√≥n y la reproducibilidad.

#### üîπ ¬øPor qu√© PyTorch Lightning separa `training_step` y `test_step`?

Porque las fases de **entrenamiento y evaluaci√≥n tienen objetivos distintos**:  

- En `training_step`, el modelo calcula la p√©rdida y ajusta los pesos mediante backpropagation.  
- En `test_step`, se **eval√∫a el rendimiento** sin modificar los par√°metros, garantizando una medici√≥n objetiva de la generalizaci√≥n del modelo.

#### üîπ ¬øCu√°l framework elegir√≠as para cada escenario?

| Escenario                  | Framework recomendado    | Justificaci√≥n                                                                                 |
|----------------------------|--------------------------|-----------------------------------------------------------------------------------------------|
| **Prototipo r√°pido**       | üß© *Scikit-learn*       | Permite validar ideas de forma √°gil y con poco c√≥digo.                                         |
| **Modelo en producci√≥n**   | ‚öôÔ∏è *TensorFlow / Keras* | Ofrece soporte industrial, escalabilidad y despliegue en servidores o dispositivos m√≥viles.    |
| **Investigaci√≥n avanzada** | üî¨ *PyTorch Lightning*  | Proporciona flexibilidad total, control del flujo y soporte para experimentaci√≥n reproducible. |

#### üîπ ¬øPor qu√© el error `mat1 and mat2 shapes cannot be multiplied` es com√∫n en PyTorch?

Este error ocurre cuando **las dimensiones de entrada del dataset no coinciden con las de la primera capa del modelo**. 

PyTorch exige que el tama√±o de las columnas del tensor de entrada sea igual al n√∫mero de **neuronas de entrada** en la red; cualquier discrepancia genera ese error.

#### üîπ ¬øQu√© significa el par√°metro `deterministic=True` en `PyTorch Lightning Trainer`?

Establece un **modo determinista** que garantiza que los resultados sean **reproducibles** entre ejecuciones, fijando semillas aleatorias y deshabilitando operaciones no deterministas.  

Esto es √∫til para **experimentos cient√≠ficos** donde se requiere consistencia total en los resultados.

#### üîπ ¬øPor qu√© TensorFlow muestra curvas de `loss` y `val_loss` durante el entrenamiento?

Porque permite **visualizar el progreso del modelo** y detectar problemas como **overfitting**:  

- Si la p√©rdida de entrenamiento sigue bajando pero la de validaci√≥n sube, el modelo est√° **memorizando los datos** y perdiendo capacidad de generalizaci√≥n.  

Estas curvas son esenciales para ajustar hiperpar√°metros como regularizaci√≥n o n√∫mero de √©pocas.

#### üîπ ¬øCu√°l es la diferencia entre `trainer.test()` y `trainer.predict()` en PyTorch Lightning?

- `trainer.test()` ejecuta el conjunto de pruebas y **devuelve m√©tricas de evaluaci√≥n** (p√©rdida, precisi√≥n, etc.).  
- `trainer.predict()` realiza **predicciones puras**, devolviendo √∫nicamente las salidas del modelo sin calcular m√©tricas.

#### üîπ ¬øPor qu√© sklearn MLP es m√°s f√°cil pero menos flexible?

Porque abstrae la mayor parte del proceso de entrenamiento, inicializaci√≥n y optimizaci√≥n, lo que **reduce la complejidad pero limita la personalizaci√≥n**.  
A diferencia de TensorFlow o PyTorch, **no permite modificar f√°cilmente la arquitectura, funciones de p√©rdida o ciclo de entrenamiento**, sacrificando flexibilidad en favor de simplicidad.

---

## Experimento adicional

Ver art√≠culo extra: [**Limitaciones del Perceptr√≥n en C√≠rculos Conc√©ntricos*](Extra-Circulos-Concentricos.md)

Este experimento complementario muestra c√≥mo un perceptr√≥n simple falla al clasificar datos no lineales (c√≠rculos conc√©ntricos), destacando la importancia de las redes MLP para resolver este tipo de problemas.

---

## Reflexi√≥n

La presente pr√°ctica tuvo como objetivo principal explorar las capacidades de un **perceptr√≥n** b√°sico y c√≥mo evoluciona hacia redes neuronales m√°s complejas, como las **redes neuronales multicapa (MLP)**, para resolver problemas de clasificaci√≥n m√°s complejos. Comenzamos comprendiendo las limitaciones del perceptr√≥n simple con problemas como **AND**, **OR** y **NOT**, que son linealmente separables, y luego abordamos el cl√°sico problema **XOR**, que demuestra la incapacidad del perceptr√≥n para manejar datos no lineales.

Al implementar una red neuronal multicapa (MLP), pudimos observar c√≥mo este modelo puede superar las limitaciones del perceptr√≥n simple, resolviendo problemas no lineales como **XOR**. La implementaci√≥n de redes neuronales m√°s profundas permiti√≥ visualizar la capacidad de estas redes para aprender representaciones m√°s complejas de los datos y crear fronteras de decisi√≥n no lineales, lo que es esencial para la clasificaci√≥n de patrones complejos en tareas reales.

El uso de **frameworks como Scikit-learn**, **TensorFlow** y **PyTorch Lightning** permiti√≥ comparar diferentes enfoques para resolver problemas de clasificaci√≥n, destacando las ventajas y limitaciones de cada uno en t√©rminos de eficiencia y flexibilidad. Esto subraya la importancia de elegir la herramienta adecuada seg√∫n el tipo de problema y los requisitos de rendimiento.

En conclusi√≥n, esta pr√°ctica fue fundamental para entender la evoluci√≥n de los modelos de redes neuronales y su aplicabilidad en la resoluci√≥n de problemas reales. Adem√°s, puso de relieve la importancia de las **redes neuronales multicapa** en el aprendizaje profundo y la clasificaci√≥n de datos no lineales, ofreciendo una visi√≥n valiosa sobre las capacidades y el impacto de las redes neuronales en el √°mbito del aprendizaje autom√°tico.

---
## Evidencias
* [C√≥digo ejecutado por partes en Google Colab](https://colab.research.google.com/drive/1B0b8fH3DJB6KTvSEe_C2nEhoPJp-ImGx?usp=sharing)


### Gr√°fica 1 - Perceptr√≥n AND:
![Perceptr√≥n AND](image.png)

### Gr√°fica 2 - Perceptr√≥n OR:
![Perceptr√≥n OR](image1.png)

### Gr√°fica 3 - Perceptr√≥n NOT:
![Perceptr√≥n NOT](image2.png)

### Gr√°fica 4 - Perceptr√≥n XOR:
![Perceptr√≥n XOR](image3.png)

### Gr√°fica 5 - Arquitectura MLP para XOR:
![Arquitectura MLP para XOR](image4.png)

### Gr√°fica 6 - Superficie de decisi√≥n XOR:
![Superficie de decisi√≥n XOR](image5.png)

### Gr√°fica 7 - P√©rdida y precisi√≥n durante entrenamiento:
![P√©rdida y precisi√≥n durante entrenamiento](image6.png)

### Gr√°fica 8 - Matriz de Confusi√≥n Comparativa:
![Matriz de Confusi√≥n Comparativa](image7.png)



---

## Referencias

- Goodfellow, I., Bengio, Y., & Courville, A. (2016). *Deep Learning*. MIT Press.
- Chollet, F. (2017). *Deep Learning with Python*. Manning Publications.
- PyTorch Lightning. (2020). *PyTorch Lightning Documentation*. Retrieved from [https://pytorch-lightning.readthedocs.io/en/stable/](https://pytorch-lightning.readthedocs.io/en/stable/)
- TensorFlow. (2020). *TensorFlow Documentation*. Retrieved from [https://www.tensorflow.org/learn](https://www.tensorflow.org/learn)
- Scikit-learn. (2020). *Scikit-learn Documentation*. Retrieved from [https://scikit-learn.org/stable/](https://scikit-learn.org/stable/)