---

title: "Pr√°ctica 4 ‚Äî Regresi√≥n Lineal"
date: 2025-09-16
----------------

# Pr√°ctica 4 ‚Äî Regresi√≥n Lineal y Log√≠stica 

## Contexto

- En esta pr√°ctica exploramos dos enfoques fundamentales de *Machine Learning supervisado*:  
1. **Regresi√≥n lineal** aplicada al dataset **Boston Housing**, para predecir valores continuos (precio de casas).  
2. **Regresi√≥n log√≠stica** aplicada al dataset **Breast Cancer**, para clasificar tumores como **benignos o malignos**.  
- El objetivo fue no solo aplicar modelos, sino tambi√©n comprender sus diferencias, interpretar m√©tricas y reflexionar sobre el valor pr√°ctico que aportan en distintos contextos: econ√≥mico y m√©dico.  

## Marco Te√≥rico

**Machine Learning (ML)** es la disciplina que ense√±a a las computadoras a aprender patrones a partir de datos para realizar predicciones. Su funcionamiento se inspira en c√≥mo aprende el cerebro humano: observar muchos ejemplos, detectar patrones y luego aplicarlos a casos nuevos.

### Tipos de aprendizaje
- **Supervisado**: el modelo aprende a partir de ejemplos con etiquetas (ej.: predecir el precio de una casa, clasificar un tumor como benigno o maligno).  
- **No supervisado**: el modelo busca patrones ocultos en datos sin etiquetas (ej.: segmentaci√≥n de clientes).  
- **Semi-supervisado**: combinaci√≥n de ambos enfoques, √∫til cuando hay pocas etiquetas.  
- **Reinforcement learning**: el modelo (agente) aprende a partir de prueba y error en un entorno.

### Proceso CRISP-DM
El ciclo t√≠pico de un proyecto de ML sigue estos pasos:
1. **Comprensi√≥n del negocio**  
2. **Comprensi√≥n de los datos**  
3. **Preparaci√≥n de datos**  
4. **Modelado**  
5. **Evaluaci√≥n**  
6. **Despliegue**  

### Conceptos clave
- **Train/Test Split**: separar los datos en entrenamiento y prueba permite evaluar la capacidad de generalizaci√≥n del modelo.  
- **M√©tricas en regresi√≥n**: MAE, MSE, RMSE, R¬≤.  
- **M√©tricas en clasificaci√≥n**: Accuracy, Precision, Recall, F1-score y matriz de confusi√≥n.  

### Modelos utilizados
- **Regresi√≥n lineal**: predice valores continuos a partir de una relaci√≥n lineal entre variables.  
- **Regresi√≥n log√≠stica**: modelo lineal que usa funci√≥n sigmoide para generar probabilidades y clasificar en categor√≠as binarias.  


## Objetivos

- Aprender a **cargar y explorar datasets reales**.  
- Diferenciar entre problemas de **regresi√≥n (n√∫meros continuos)** y **clasificaci√≥n (categor√≠as)**.  
- Entrenar modelos b√°sicos de **regresi√≥n lineal** y **log√≠stica** con *Scikit-learn*.  
- Evaluar modelos usando m√©tricas apropiadas en cada caso.  
- Entender la importancia de separar datos en **entrenamiento y prueba** para evitar el sobreajuste.  
- Relacionar los resultados con **interpretaciones pr√°cticas** en contextos reales.  

## Actividades (con tiempos estimados)

| Actividad                         | Tiempo | Resultado esperado                                  |
| --------------------------------- | :----: | --------------------------------------------------- |
| Setup inicial                     |   5m   | Librer√≠as cargadas y entorno listo.                 |
| Cargar Dataset de Boston Housing  |   5m   | X con 13 features, y con precios                    |
| Entrenamiento de regresi√≥n lineal |   20m  | Modelo entrenado y predicciones                     |
| Bonus                             |   10m  |  Definiciones completas                             |
| Cargar datos m√©dicos              |   5m   |Dataset con 569 pacientes y 30 caracter√≠sticas listo |
| Entrenar regresi√≥n log√≠stica      |   20m  | Modelo entrenado y predicciones                     |
| Bonus                             |   5m   |  Preguntas contestadas                              |
| Preguntas de reflexi√≥n            |   15m  |   Reflexionar sobre lo hecho en la pr√°ctica         |
| Comparaci√≥n simple                |   10m  | Comparar las dos regresiones                        |
| Reflexi√≥n final                   |   15m  |  Conclusiones sobre la pr√°ctica                     |

## Desarrollo

### üè† 1. Carga del dataset

 - üîß Se utiliz√≥ el dataset **Boston Housing** disponible en `sklearn.datasets`. Contiene 506 observaciones y 13 variables predictoras como: `CRIM` (√≠ndice de criminalidad), `ZN` (proporci√≥n de terrenos residenciales), `NOX` (concentraci√≥n de √≥xidos de nitr√≥geno), entre otras. La variable objetivo es `MEDV`, que indica el valor medio de las casas.

#### üí° PISTAS:
- **LinearRegression**se usa para el modelo de regresi√≥n lineal (seg√∫n documentaci√≥n de sklearn).
- **train_test_split** permite dividir los datos en entrenamiento y prueba.
- Las m√©tricas (**mean_squared_error, mean_absolute_error, r2_score**) son las adecuadas para evaluar modelos de regresi√≥n.

### üè† 2. Divisi√≥n en entrenamiento y prueba

#### ü§ñ Explicaci√≥n de blanks:
- Se elimina medv de X porque es la variable que queremos predecir.
- y = boston_data['medv'] toma √∫nicamente la columna de precios.

#### ‚úÖ Resultado de ejecuci√≥n:
- Dataset con 506 filas y 14 columnas.
- X ‚Üí 13 variables independientes.
- y ‚Üí vector con los precios (medv).
- Rango de precios: $5k ‚Äì $50k.

### üè† 3. Entrenamiento del modelo

- üî¨ Se entren√≥ un modelo de **regresi√≥n lineal** con `LinearRegression` de Scikit-learn. El modelo estima una relaci√≥n lineal entre las variables predictoras y el precio medio de las viviendas.

#### ü§ñ Explicaci√≥n de blanks:
- **LinearRegression()** crea el modelo.
- **.fit(X_train, y_train)** entrena el modelo usando datos de entrenamiento.
- **.predict(X_test)** genera predicciones sobre datos no vistos.

#### ‚úÖ Resultado de ejecuci√≥n:
- Entrenamiento sobre 404 casas.
- Prueba sobre 102 casas.
- Predicciones generadas exitosamente.

- üîç Se aplic√≥ el modelo entrenado sobre los datos de prueba, obteniendo predicciones de `MEDV` que luego fueron comparadas con los valores reales.

#### M√©tricas de evaluaci√≥n:
- **MAE:** $3.19k
- **MSE:** 24.29
- **RMSE:** $4.93k
- **R¬≤:** 0.669
- **MAPE:** 16.9%

#### Interpretaci√≥n de resultados

* El **R¬≤ = 0.73** indica que el 66.9% de la variabilidad del precio medio de las casas puede explicarse por las variables incluidas en el modelo.
* Un **RMSE ‚âà 4.93** significa que, en promedio, las predicciones del modelo tienen un error de ¬±5 mil d√≥lares respecto al valor real de las viviendas.
* El **MAE = 3.19** refuerza la idea de que el modelo se aproxima bastante a los valores reales, aunque con cierto margen de error.
* El modelo es relativamente bueno, pero no perfecto. Factores no capturados en el dataset (ejemplo: din√°mica econ√≥mica, ubicaci√≥n exacta de las casas) explican el error residual.

### üìö BONUS

üìà Para evaluar el rendimiento se calcularon las siguientes m√©tricas:

* **MSE (Mean Squared Error)**: Promedio de los errores al cuadrado, penaliza m√°s los errores grandes.
* **RMSE (Root Mean Squared Error)**: Ra√≠z cuadrada del MSE, vuelve a las unidades originales del problema.
* **MAE (Mean Absolute Error)**: Promedio de los errores absolutos sin importar si son positivos o negativos.
* **R¬≤ (Coeficiente de determinaci√≥n)**: Indica qu√© porcentaje de la variabilidad es explicada por el modelo (0-1, donde 1 es perfecto).
* **MAPE**: Error porcentual promedio, √∫til para comparar modelos con diferentes escalas.

### üè† 4. Cargar datos m√©dicos 
- üìã Contexto de negocio (CRISP-DM: Business Understanding)
- Problema: Un hospital necesita asistencia automatizada para diagn√≥stico de c√°ncer de mama.
- Objetivo: Clasificar tumores como benignos (1) o malignos (0) a partir de caracter√≠sticas celulares.
- Variables: 30 caracter√≠sticas de n√∫cleos celulares (ej: radio, textura, per√≠metro, √°rea, suavidad, etc.).
- Valor para el negocio: Proveer soporte a m√©dicos reduciendo tiempo de an√°lisis, aumentando precisi√≥n y sirviendo como segunda opini√≥n autom√°tica.
#### ‚úÖ Resultado de ejecuci√≥n:
- Tumores malignos: 212 casos (‚âà 37%)
- Tumores benignos: 357 casos (‚âà 63%)
- Esta distribuci√≥n muestra que el dataset no est√° perfectamente balanceado, aunque la diferencia no es extrema. Aun as√≠, es importante tenerlo en cuenta porque podr√≠a influir en el rendimiento de los clasificadores, especialmente en m√©tricas como precisi√≥n, recall y F1-score.

### üè† 5. Entrenar regresi√≥n log√≠stica:

#### üí° PISTAS:
- **train_test_split** se utiliza para dividir el dataset en entrenamiento (80%) y prueba (20%), garantizando aleatoriedad con random_state=42.
- **LogisticRegression** es la clase de sklearn.linear_model para entrenar un modelo de regresi√≥n log√≠stica. El par√°metro max_iter=5000 asegura que el algoritmo tenga suficiente n√∫mero de iteraciones para converger.
- Los m√©todos **.fit()** y **.predict()** funcionan igual que en regresi√≥n lineal.
- Las m√©tricas usadas son:
* accuracy_score: proporci√≥n de predicciones correctas.
* precision_score: proporci√≥n de verdaderos positivos sobre todos los positivos predichos.
* recall_score: proporci√≥n de verdaderos positivos sobre todos los positivos reales.
* f1_score: media arm√≥nica entre precisi√≥n y recall.
- **confusion_matrix** permite ver los aciertos y errores en t√©rminos de verdaderos/falsos positivos y negativos.
- **classification_report** genera un desglose detallado por clase.

#### ‚úÖ Resultado de ejecuci√≥n:

- Entrenamiento: 455 pacientes
- Prueba: 114 pacientes

- M√©tricas de clasificaci√≥n:
- Accuracy: 95.6%
- Precision: 94.6%
- Recall: 98.6%
- F1-Score: 0.966

- Verdaderos Negativos: 39
- Falsos Positivos: 4

- Falsos Negativos: 1
- Verdaderos Positivos: 70

#### Interpretaci√≥n de resultados

- El modelo tiene una alta exactitud (95.6%), lo que indica que clasifica correctamente la mayor√≠a de los casos.

- Precisi√≥n (94.6%): de los tumores predichos como benignos, el 94.6% lo eran realmente.

- Recall (98.6%): de todos los tumores benignos reales, el modelo identific√≥ casi todos.

- F1-Score (0.966): muestra un excelente balance entre precisi√≥n y recall.

- La matriz de confusi√≥n indica que solo hubo 5 errores en 114 predicciones (4 falsos positivos y 1 falso negativo).

- Desde un punto de vista m√©dico, el bajo n√∫mero de falsos negativos (solo 1) es crucial, ya que significa que casi no se dejan pasar casos malignos como benignos, reduciendo el riesgo para los pacientes.

### üéÅ  BONUS: ¬øQu√© significan las m√©tricas de clasificaci√≥n?

- **Accuracy:** Porcentaje de predicciones **correctas** sobre el total.  
- **Precision:** De todas las predicciones **positivas**, ¬øcu√°ntas fueron realmente correctas? (94,6%)
- **Recall (Sensibilidad):** De todos los casos **positivos reales**, ¬øcu√°ntos detectamos? (98,6%)
- **F1-Score:** Promedio **arm√≥nico** entre precision y recall.  
- **Matriz de Confusi√≥n:** Tabla que muestra **valores reales** vs **valores predichos**.  

### üß† Paso 6: Preguntas de Reflexi√≥n  

**1. ¬øCu√°l es la diferencia principal entre regresi√≥n lineal y log√≠stica?**  
- La **regresi√≥n lineal** predice valores **continuos** (por ejemplo, el precio de una casa).  
- La **regresi√≥n log√≠stica** predice valores **categ√≥ricos/binarios** (por ejemplo, benigno vs maligno).  

**2. ¬øPor qu√© dividimos los datos en entrenamiento y prueba?**  
- Para asegurarnos de que el modelo no solo memorice los datos, sino que tambi√©n pueda **generalizar a datos nuevos**.  
- El **train/test split** permite entrenar con una parte de los datos y luego evaluar el desempe√±o en ejemplos que el modelo nunca vio.  


**3. ¬øQu√© significa una exactitud del 95%?**  
- Significa que de cada **100 pacientes**, el modelo clasifica correctamente a **95**.  
- En nuestro caso, de 114 pacientes de prueba, el modelo acert√≥ en 109 y se equivoc√≥ en 5.  


**4. ¬øCu√°l es m√°s peligroso: predecir "benigno" cuando es "maligno", o al rev√©s?**  
- Es **m√°s peligroso predecir "benigno" cuando en realidad es maligno**, porque el paciente podr√≠a no recibir tratamiento a tiempo.  
- En cambio, predecir "maligno" cuando era benigno genera preocupaci√≥n innecesaria, pero no pone en riesgo la vida del paciente.  

### üîç Paso 7: Comparaci√≥n Simple  

| Aspecto            | Regresi√≥n Lineal                         | Regresi√≥n Log√≠stica                          |
| ------------------ | ---------------------------------------- | -------------------------------------------- |
| Qu√© predice        | Valores num√©ricos continuos              | Categor√≠as (clases, ej. 0 o 1)               |
| Ejemplo de uso     | Precio de una casa en d√≥lares            | Diagn√≥stico de tumor: benigno/maligno        |
| Rango de salida    | N√∫meros reales (-‚àû, +‚àû)                  | Probabilidades entre 0 y 1 ‚Üí luego clase 0/1 |
| M√©trica principal  | Error (MAE, MSE, RMSE, R¬≤, MAPE)         | Exactitud, Precisi√≥n, Recall, F1-Score       |

### üìù Paso 8: Reflexi√≥n Final  

**1. ¬øCu√°l modelo usar√≠as para predecir el salario de un empleado?**  
- Usar√≠a **regresi√≥n lineal**, porque el salario es un **valor continuo** que puede tomar muchos posibles montos.  

**2. ¬øCu√°l modelo usar√≠as para predecir si un email es spam?**  
- Usar√≠a **regresi√≥n log√≠stica**, porque el problema es de **clasificaci√≥n binaria** (spam o no spam).  

**3. ¬øPor qu√© es importante separar datos de entrenamiento y prueba?**  
- Porque permite comprobar si el modelo **generaliza bien a datos nuevos**.  
- Si solo usamos datos de entrenamiento, el modelo puede ‚Äúmemorizar‚Äù (overfitting).  
- Con datos de prueba podemos evaluar el **desempe√±o real** en situaciones que no vio durante el entrenamiento.  


## Evidencias

* [C√≥digo completo para ejecutar en Google Colab](https://colab.research.google.com/drive/14INyAU9dGAbxu2TPs-GuP_bgt4n8zkKS?usp=sharing)

### C√≥digo con los espacios en blanco rellenados que se ejecut√≥:

```python
# 1. Setup inicial:
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.model_selection import train_test_split

# 2. Cargar dataset
X = boston_data.drop('medv', axis=1)  # Todas las columnas EXCEPTO la que queremos predecir
y = boston_data['medv']                # Solo la columna que queremos predecir

# 3. Entrenar modelo
modelo_regresion = LinearRegression()
modelo_regresion.fit(X_train, y_train)

predicciones = modelo_regresion.predict(X_test)

mae = mean_absolute_error(y_test, predicciones)
mse = mean_squared_error(y_test, predicciones)
r2 = r2_score(y_test, predicciones)

# 6. Entrenar regresi√≥n log√≠stica
X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split( X_cancer, y_cancer, test_size=0.2, random_state=42
)

modelo_clasificacion = LogisticRegression(max_iter=5000, random_state=42)
modelo_clasificacion.fit(X_train_cancer, y_train_cancer)

predicciones_cancer = modelo_clasificacion.predict(X_test_cancer)

precision = precision_score(y_test_cancer, predicciones_cancer)
recall = recall_score(y_test_cancer, predicciones_cancer)
f1 = f1_score(y_test_cancer, predicciones_cancer)

matriz_confusion = confusion_matrix(y_test_cancer, predicciones_cancer)

print(classification_report(y_test_cancer, predicciones_cancer, target_names=['Maligno', 'Benigno']))

   
```


## Reflexi√≥n
A lo largo de la pr√°ctica se aprendi√≥:  

- **C√≥mo cargar y explorar datos reales** de distintas √°reas (econom√≠a y salud).  
- La **diferencia clave entre regresi√≥n lineal y log√≠stica**: valores continuos vs categor√≠as.  
- A entrenar modelos de *machine learning* desde cero con pasos b√°sicos (`train_test_split`, `.fit()`, `.predict()`).  
- La importancia de **elegir las m√©tricas adecuadas** seg√∫n el tipo de problema (MAE, RMSE, R¬≤ en regresi√≥n; accuracy, precision, recall y F1 en clasificaci√≥n).  
- El valor de separar datos en **entrenamiento y prueba** para evaluar el rendimiento real de un modelo.  

- En conclusi√≥n, la pr√°ctica permiti√≥ desarrollar una visi√≥n clara de c√≥mo aplicar modelos sencillos de ML y, sobre todo, **interpretar sus resultados en contextos reales**: desde estimar precios de viviendas hasta apoyar diagn√≥sticos m√©dicos.  

---
## Referencias

- [Scikit-learn ‚Äî Linear Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)  
- [Scikit-learn ‚Äî Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)  
- [M√©tricas de evaluaci√≥n en Scikit-learn](https://scikit-learn.org/stable/modules/model_evaluation.html)  
- Harrison, D. & Rubinfeld, D.L. (1978). *Hedonic prices and the demand for clean air*. Journal of Environmental Economics and Management, 5(1), 81‚Äì102. (Dataset original Boston Housing)  
- [UCI Machine Learning Repository ‚Äî Breast Cancer Wisconsin Dataset](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)  